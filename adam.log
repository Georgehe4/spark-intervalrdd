2015-10-27 16:25:24 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-27 16:25:25 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-27 16:25:25 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-27 16:25:25 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-27 16:25:25 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-27 16:25:26 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-27 16:25:27 INFO  Remoting:74 - Starting remoting
2015-10-27 16:25:27 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:54473]
2015-10-27 16:25:27 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 54473.
2015-10-27 16:25:27 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-27 16:25:27 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-27 16:25:27 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-10b29551-2c68-4a9b-98c0-b96f28ad9e51
2015-10-27 16:25:27 INFO  MemoryStore:59 - MemoryStore started with capacity 491.7 MB
2015-10-27 16:25:27 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-066c5814-7d0e-4058-bbb3-9be51f84c1b2/httpd-8e67f3a2-5fd8-4cb0-9180-9df88c412951
2015-10-27 16:25:27 INFO  HttpServer:59 - Starting HTTP Server
2015-10-27 16:25:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-27 16:25:27 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:54474
2015-10-27 16:25:27 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 54474.
2015-10-27 16:25:27 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-27 16:25:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-27 16:25:27 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-27 16:25:27 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-27 16:25:27 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-27 16:25:27 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-27 16:25:27 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-27 16:25:27 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54475.
2015-10-27 16:25:27 INFO  NettyBlockTransferService:59 - Server created on 54475
2015-10-27 16:25:27 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-27 16:25:27 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:54475 with 491.7 MB RAM, BlockManagerId(driver, localhost, 54475)
2015-10-27 16:25:27 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-27 16:25:28 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-27 16:25:28 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-27 16:25:28 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=515553361
2015-10-27 16:25:28 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 491.7 MB)
2015-10-27 16:25:28 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=515553361
2015-10-27 16:25:28 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 491.7 MB)
2015-10-27 16:25:28 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:54475 (size: 1631.0 B, free: 491.7 MB)
2015-10-27 16:25:28 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-27 16:25:28 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-27 16:25:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-27 16:25:28 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-27 16:25:28 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 112 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.147 s
2015-10-27 16:25:29 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-27 16:25:29 INFO  DAGScheduler:59 - running: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - failed: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:178), which is now runnable
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:54475 (size: 2.2 KB, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:178)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 86 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.087 s
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.527933 s
2015-10-27 16:25:29 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-27 16:25:29 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-27 16:25:29 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:178), which has no missing parents
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:54475 (size: 2.2 KB, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:178)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 7 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.007 s
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.020523 s
2015-10-27 16:25:29 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-27 16:25:29 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 491.6 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:54475 (size: 1631.0 B, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 491.6 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 491.6 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:54475 (size: 1633.0 B, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.016 s
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 15 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - failed: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 16 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.023 s
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-27 16:25:29 INFO  DAGScheduler:59 - running: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - failed: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 491.6 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 491.6 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:54475 (size: 2.9 KB, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 19 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.019 s
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.076743 s
2015-10-27 17:00:50 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-27 17:00:51 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-27 17:00:51 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-27 17:00:51 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-27 17:00:51 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-27 17:00:51 INFO  BlockManager:59 - BlockManager stopped
2015-10-27 17:00:51 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-27 17:00:51 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-27 17:00:51 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-27 17:00:51 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-27 17:00:51 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-066c5814-7d0e-4058-bbb3-9be51f84c1b2
2015-10-28 14:02:43 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-28 14:02:44 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-28 14:02:44 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-28 14:02:44 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-28 14:02:44 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-28 14:02:44 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-28 14:02:44 INFO  Remoting:74 - Starting remoting
2015-10-28 14:02:45 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.105.138.61:58691]
2015-10-28 14:02:45 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 58691.
2015-10-28 14:02:45 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-28 14:02:45 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-28 14:02:45 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-0033a052-3c9e-4a08-96f5-4c07e0f0fa8d
2015-10-28 14:02:45 INFO  MemoryStore:59 - MemoryStore started with capacity 508.1 MB
2015-10-28 14:02:45 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-694b33c0-8107-4063-a224-1c0a5e554b55/httpd-a4e95429-9ed4-4ab6-93f0-6efc4b1ee23a
2015-10-28 14:02:45 INFO  HttpServer:59 - Starting HTTP Server
2015-10-28 14:02:45 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-28 14:02:45 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:58692
2015-10-28 14:02:45 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 58692.
2015-10-28 14:02:45 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-28 14:02:45 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-28 14:02:45 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-28 14:02:45 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-28 14:02:45 INFO  SparkUI:59 - Started SparkUI at http://10.105.138.61:4040
2015-10-28 14:02:45 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-28 14:02:45 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-28 14:02:45 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58693.
2015-10-28 14:02:45 INFO  NettyBlockTransferService:59 - Server created on 58693
2015-10-28 14:02:45 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-28 14:02:45 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:58693 with 508.1 MB RAM, BlockManagerId(driver, localhost, 58693)
2015-10-28 14:02:45 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-28 14:02:46 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-28 14:02:46 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:58693 (size: 1631.0 B, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 100 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.120 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-28 14:02:46 INFO  DAGScheduler:59 - running: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - failed: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:58693 (size: 2.2 KB, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 51 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.052 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.457130 s
2015-10-28 14:02:46 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-28 14:02:46 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-28 14:02:46 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:58693 (size: 2.2 KB, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 12 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.012 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.026363 s
2015-10-28 14:02:46 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-28 14:02:46 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:58693 (size: 1631.0 B, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:58693 (size: 1633.0 B, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 19 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.019 s
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-28 14:02:46 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - failed: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 12 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.021 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-28 14:02:46 INFO  DAGScheduler:59 - running: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - failed: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:58693 (size: 2.9 KB, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 19 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.019 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.077835 s
2015-10-28 14:27:48 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-28 14:27:49 INFO  SparkUI:59 - Stopped Spark web UI at http://10.105.138.61:4040
2015-10-28 14:27:49 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-28 14:27:49 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-28 14:27:49 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-28 14:27:49 INFO  BlockManager:59 - BlockManager stopped
2015-10-28 14:27:49 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-28 14:27:49 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-28 14:27:49 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-28 14:27:49 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-28 14:27:49 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-694b33c0-8107-4063-a224-1c0a5e554b55
2015-10-29 11:37:34 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 11:37:34 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 11:37:34 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 11:37:34 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 11:37:34 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 11:37:35 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 11:37:35 INFO  Remoting:74 - Starting remoting
2015-10-29 11:37:35 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:64790]
2015-10-29 11:37:35 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 64790.
2015-10-29 11:37:35 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 11:37:35 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 11:37:35 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-4902fe2f-18a3-4157-b3b4-d5e4bfe18011
2015-10-29 11:37:35 INFO  MemoryStore:59 - MemoryStore started with capacity 507.6 MB
2015-10-29 11:37:35 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-858ab31d-7aaf-440c-9cec-38e9b56988f0/httpd-6792d7ff-967d-4d59-be98-b9546abd08e9
2015-10-29 11:37:35 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 11:37:35 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 11:37:35 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:64791
2015-10-29 11:37:35 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 64791.
2015-10-29 11:37:35 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 11:37:35 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 11:37:35 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 11:37:35 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 11:37:35 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 11:37:35 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 11:37:35 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 11:37:36 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64792.
2015-10-29 11:37:36 INFO  NettyBlockTransferService:59 - Server created on 64792
2015-10-29 11:37:36 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 11:37:36 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:64792 with 507.6 MB RAM, BlockManagerId(driver, localhost, 64792)
2015-10-29 11:37:36 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 11:37:36 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 11:37:36 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 11:37:36 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=532257177
2015-10-29 11:37:36 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 507.6 MB)
2015-10-29 11:37:36 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=532257177
2015-10-29 11:37:36 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 507.6 MB)
2015-10-29 11:37:36 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:64792 (size: 1631.0 B, free: 507.6 MB)
2015-10-29 11:37:36 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 11:37:36 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 11:37:36 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 11:37:36 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 11:37:36 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 11:37:36 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 84 ms on localhost (1/1)
2015-10-29 11:37:36 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 11:37:36 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.099 s
2015-10-29 11:37:36 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 11:37:36 INFO  DAGScheduler:59 - running: Set()
2015-10-29 11:37:36 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 11:37:36 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=532257177
2015-10-29 11:37:36 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 507.6 MB)
2015-10-29 11:37:36 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=532257177
2015-10-29 11:37:36 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 507.6 MB)
2015-10-29 11:37:36 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:64792 (size: 2.2 KB, free: 507.6 MB)
2015-10-29 11:37:36 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 11:37:36 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 11:37:36 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 11:37:36 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.043 s
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.380091 s
2015-10-29 11:37:37 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 11:37:37 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 11:37:37 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:64792 (size: 2.2 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 11:37:37 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 6 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.007 s
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.017999 s
2015-10-29 11:37:37 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 11:37:37 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 507.6 MB)
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:64792 (size: 1631.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 11:37:37 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 507.6 MB)
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:64792 (size: 1633.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 11:37:37 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 14 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.015 s
2015-10-29 11:37:37 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 11:37:37 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 16 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.021 s
2015-10-29 11:37:37 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 11:37:37 INFO  DAGScheduler:59 - running: Set()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:64792 (size: 2.9 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 11:37:37 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 19 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.019 s
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.076125 s
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_5_piece0 on localhost:64792 in memory (size: 2.9 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 6
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:64792 in memory (size: 1633.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:64792 in memory (size: 1631.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:64792 in memory (size: 2.2 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:64792 in memory (size: 2.2 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:64792 in memory (size: 1631.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:28:30 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:28:30 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:28:30 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:28:30 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:28:30 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:28:30 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:28:31 INFO  Remoting:74 - Starting remoting
2015-10-29 13:28:31 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:65516]
2015-10-29 13:28:31 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 65516.
2015-10-29 13:28:31 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:28:31 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:28:31 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-d338b392-227a-47cc-96ff-4f948f17aa19
2015-10-29 13:28:31 INFO  MemoryStore:59 - MemoryStore started with capacity 507.1 MB
2015-10-29 13:28:31 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-c76c87fd-9209-45de-8656-d48d028b0a6b/httpd-b33cb172-f05c-4977-8085-9dfbdf86f88e
2015-10-29 13:28:31 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:28:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:28:31 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:65517
2015-10-29 13:28:31 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 65517.
2015-10-29 13:28:31 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:28:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:28:31 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:28:31 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@43c047b2: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:28:31 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:28:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:28:31 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 13:28:31 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 13:28:31 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 13:28:31 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:28:31 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:28:31 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65518.
2015-10-29 13:28:31 INFO  NettyBlockTransferService:59 - Server created on 65518
2015-10-29 13:28:31 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:28:31 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:65518 with 507.1 MB RAM, BlockManagerId(driver, localhost, 65518)
2015-10-29 13:28:31 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:28:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:28:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 507.1 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 507.1 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:65518 (size: 1631.0 B, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 69 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.083 s
2015-10-29 13:28:32 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:28:32 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 507.1 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:65518 (size: 2.2 KB, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 47 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.047 s
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.281368 s
2015-10-29 13:28:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:28:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:28:32 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:65518 (size: 2.2 KB, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 7 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.008 s
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.020885 s
2015-10-29 13:28:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:28:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:65518 (size: 1631.0 B, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:65518 (size: 1633.0 B, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 17 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.018 s
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:28:32 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 9 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.016 s
2015-10-29 13:28:32 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:28:32 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:65518 (size: 2.9 KB, free: 507.0 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 19 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.020 s
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.064359 s
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_5_piece0 on localhost:65518 in memory (size: 2.9 KB, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 6
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:65518 in memory (size: 1633.0 B, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:65518 in memory (size: 1631.0 B, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:65518 in memory (size: 2.2 KB, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:65518 in memory (size: 2.2 KB, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:65518 in memory (size: 1631.0 B, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:29:55 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 13:29:55 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:29:55 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 13:29:55 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 13:29:55 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 13:29:55 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 13:29:55 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 13:29:55 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 13:29:55 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 13:29:55 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 13:29:55 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 13:29:55 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 13:29:55 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 13:29:55 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 13:29:55 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 13:29:55 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 13:29:55 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 13:29:55 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 13:29:55 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 13:29:55 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-c76c87fd-9209-45de-8656-d48d028b0a6b
2015-10-29 13:29:55 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 13:29:55 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-858ab31d-7aaf-440c-9cec-38e9b56988f0
2015-10-29 13:31:41 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:31:41 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:31:41 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:31:41 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:31:41 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:31:42 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:31:42 INFO  Remoting:74 - Starting remoting
2015-10-29 13:31:43 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:65534]
2015-10-29 13:31:43 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 65534.
2015-10-29 13:31:43 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:31:43 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:31:43 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-ba79c69b-c2f7-4b33-a992-a2220d9cfaed
2015-10-29 13:31:43 INFO  MemoryStore:59 - MemoryStore started with capacity 530.0 MB
2015-10-29 13:31:43 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-47efdc31-ca72-42ae-94cd-993bd0b24d49/httpd-e358d1f7-5726-4126-8c0c-d4ac6361a2c9
2015-10-29 13:31:43 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:31:43 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:31:43 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:65535
2015-10-29 13:31:43 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 65535.
2015-10-29 13:31:43 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:31:43 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:31:43 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 13:31:43 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 13:31:43 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 13:31:43 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:31:43 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:31:43 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49152.
2015-10-29 13:31:43 INFO  NettyBlockTransferService:59 - Server created on 49152
2015-10-29 13:31:43 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:31:43 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49152 with 530.0 MB RAM, BlockManagerId(driver, localhost, 49152)
2015-10-29 13:31:43 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:31:44 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:31:44 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49152 (size: 1631.0 B, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 81 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.102 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:31:44 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49152 (size: 2.2 KB, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 48 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.049 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.371321 s
2015-10-29 13:31:44 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:31:44 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:31:44 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49152 (size: 2.2 KB, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 8 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.010 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.023929 s
2015-10-29 13:31:44 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:31:44 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:49152 (size: 1631.0 B, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:49152 (size: 1633.0 B, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 14 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.015 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:31:44 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 17 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.021 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:31:44 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:49152 (size: 2.9 KB, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 21 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.021 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.082858 s
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_5_piece0 on localhost:49152 in memory (size: 2.9 KB, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 6
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:49152 in memory (size: 1633.0 B, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:49152 in memory (size: 1631.0 B, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49152 in memory (size: 2.2 KB, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49152 in memory (size: 2.2 KB, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49152 in memory (size: 1631.0 B, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:36:19 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:36:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:36:19 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:36:19 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:36:19 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:36:19 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:36:19 INFO  Remoting:74 - Starting remoting
2015-10-29 13:36:20 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49154]
2015-10-29 13:36:20 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49154.
2015-10-29 13:36:20 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:36:20 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:36:20 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-ba3f6c3d-e3b7-4e48-9cec-512304303369
2015-10-29 13:36:20 INFO  MemoryStore:59 - MemoryStore started with capacity 503.3 MB
2015-10-29 13:36:20 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-091374ae-5d69-49dc-88ba-bb513234b47a/httpd-382b1eed-aace-4b43-86d9-5ce383d9757f
2015-10-29 13:36:20 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:36:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:36:20 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49155
2015-10-29 13:36:20 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49155.
2015-10-29 13:36:20 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:36:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:36:20 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:36:20 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@74cb163: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:36:20 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:36:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:36:20 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 13:36:20 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 13:36:20 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 13:36:20 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:36:20 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:36:20 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49156.
2015-10-29 13:36:20 INFO  NettyBlockTransferService:59 - Server created on 49156
2015-10-29 13:36:20 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:36:20 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49156 with 503.3 MB RAM, BlockManagerId(driver, localhost, 49156)
2015-10-29 13:36:20 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:36:21 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:36:21 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49156 (size: 1631.0 B, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 107 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.131 s
2015-10-29 13:36:21 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:36:21 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49156 (size: 2.2 KB, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.037 s
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.331664 s
2015-10-29 13:36:21 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:36:21 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:36:21 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49156 (size: 2.2 KB, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 6 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.007 s
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.017743 s
2015-10-29 13:36:21 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:36:21 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:49156 (size: 1631.0 B, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:49156 (size: 1633.0 B, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 19 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.019 s
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:36:21 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 12 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.024 s
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:36:21 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 503.2 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:49156 (size: 2.9 KB, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 16 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.016 s
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.070538 s
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:49156 in memory (size: 1631.0 B, free: 503.3 MB)
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_5_piece0 on localhost:49156 in memory (size: 2.9 KB, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 6
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:49156 in memory (size: 1633.0 B, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49156 in memory (size: 2.2 KB, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49156 in memory (size: 2.2 KB, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49156 in memory (size: 1631.0 B, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:37:26 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:37:26 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:37:26 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:37:26 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:37:26 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:37:26 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:37:26 INFO  Remoting:74 - Starting remoting
2015-10-29 13:37:26 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49157]
2015-10-29 13:37:26 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49157.
2015-10-29 13:37:26 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:37:26 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:37:26 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-1ac92025-441a-4e8a-9bb9-07c2d0a87249
2015-10-29 13:37:26 INFO  MemoryStore:59 - MemoryStore started with capacity 506.8 MB
2015-10-29 13:37:26 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1bb2b8c4-ceae-4743-b558-42967987a1e8/httpd-509c4acc-0d35-4f7c-8b1a-1d1708f57f0f
2015-10-29 13:37:26 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:37:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:37:27 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49158
2015-10-29 13:37:27 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49158.
2015-10-29 13:37:27 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:37:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:37:27 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:37:27 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@fc21a77: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:37:27 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:37:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:37:27 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:37:27 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@87485d0: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:37:27 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 13:37:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:37:27 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4042
2015-10-29 13:37:27 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4042.
2015-10-29 13:37:27 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4042
2015-10-29 13:37:27 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:37:27 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:37:27 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49159.
2015-10-29 13:37:27 INFO  NettyBlockTransferService:59 - Server created on 49159
2015-10-29 13:37:27 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:37:27 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49159 with 506.8 MB RAM, BlockManagerId(driver, localhost, 49159)
2015-10-29 13:37:27 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:37:27 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:37:27 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49159 (size: 1631.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 76 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.094 s
2015-10-29 13:37:28 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:37:28 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49159 (size: 2.2 KB, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 7 ms
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 62 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.064 s
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.302805 s
2015-10-29 13:37:28 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:37:28 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Final stage: ResultStage 4(runJob at IntervalRDD.scala:82)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2, ShuffleMapStage 3)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 2, ShuffleMapStage 3)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 2 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=10515, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=13171, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1631.0 B, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49159 (size: 1631.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 2 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 2.0 with 1 tasks
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 3 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 2.0 (TID 2)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=14802, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=17458, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1633.0 B, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:49159 (size: 1633.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 3 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 2.0 (TID 2). 1160 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 3, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 2.0 (TID 2) in 13 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ShuffleMapStage 2 (parallelize at IntervalRDDSuite.scala:146) finished in 0.013 s
2015-10-29 13:37:28 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:37:28 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 3)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - waiting: Set(ResultStage 4)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 3)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Missing parents for ResultStage 4: List(ShuffleMapStage 3)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ShuffleMapStage 3 (parallelize at IntervalRDDSuite.scala:128) finished in 0.015 s
2015-10-29 13:37:28 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:37:28 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - waiting: Set(ResultStage 4)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Missing parents for ResultStage 4: List()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting ResultStage 4 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=19091, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 5.3 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=24555, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.9 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:49159 (size: 2.9 KB, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 4 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 4, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 4)
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 4). 1161 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 4) in 14 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ResultStage 4 (runJob at IntervalRDD.scala:82) finished in 0.015 s
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.056991 s
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:49159 in memory (size: 2.9 KB, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:49159 in memory (size: 1633.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49159 in memory (size: 1631.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49159 in memory (size: 2.2 KB, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49159 in memory (size: 1631.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:48:11 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:48:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:48:11 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:48:11 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:48:11 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:48:11 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:48:11 INFO  Remoting:74 - Starting remoting
2015-10-29 13:48:11 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49291]
2015-10-29 13:48:11 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49291.
2015-10-29 13:48:11 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:48:11 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:48:11 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-da561249-88bf-4c19-8ca6-6661c1b19a21
2015-10-29 13:48:11 INFO  MemoryStore:59 - MemoryStore started with capacity 516.5 MB
2015-10-29 13:48:11 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-82d2ff8f-fa3d-41e8-a0d7-29a86d79d100/httpd-2142338d-f0b6-438e-a2e6-385620916e90
2015-10-29 13:48:11 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49292
2015-10-29 13:48:12 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49292.
2015-10-29 13:48:12 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@559a240a: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:48:12 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@5d442e10: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:48:12 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@5684954f: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:48:12 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4043
2015-10-29 13:48:12 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4043.
2015-10-29 13:48:12 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4043
2015-10-29 13:48:12 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:48:12 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:48:12 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49293.
2015-10-29 13:48:12 INFO  NettyBlockTransferService:59 - Server created on 49293
2015-10-29 13:48:12 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:48:12 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49293 with 516.5 MB RAM, BlockManagerId(driver, localhost, 49293)
2015-10-29 13:48:12 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:48:13 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:48:13 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:48:13 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=541599989
2015-10-29 13:48:13 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 516.5 MB)
2015-10-29 13:48:13 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=541599989
2015-10-29 13:48:13 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 516.5 MB)
2015-10-29 13:48:13 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49293 (size: 1631.0 B, free: 516.5 MB)
2015-10-29 13:48:13 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:48:13 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:48:13 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:48:13 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:48:13 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:48:13 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 79 ms on localhost (1/1)
2015-10-29 13:48:13 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:48:13 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.093 s
2015-10-29 13:48:13 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:48:13 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:48:13 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:48:13 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=541599989
2015-10-29 13:48:13 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 516.5 MB)
2015-10-29 13:48:13 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=541599989
2015-10-29 13:48:13 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 516.5 MB)
2015-10-29 13:48:13 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49293 (size: 2.2 KB, free: 516.5 MB)
2015-10-29 13:48:13 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:48:13 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:48:13 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:48:13 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:48:13 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:48:13 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 13:48:13 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 13:48:13 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.043 s
2015-10-29 13:48:13 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.272699 s
2015-10-29 13:55:28 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49293 in memory (size: 2.2 KB, free: 516.5 MB)
2015-10-29 13:55:28 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:55:28 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49293 in memory (size: 1631.0 B, free: 516.5 MB)
2015-10-29 13:55:28 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:55:28 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:55:57 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:55:58 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:55:58 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:55:58 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:55:58 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:55:58 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:55:58 INFO  Remoting:74 - Starting remoting
2015-10-29 13:55:58 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49379]
2015-10-29 13:55:58 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49379.
2015-10-29 13:55:58 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:55:58 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:55:58 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-af506c07-55d0-47a8-b2ac-61eddb95aeb9
2015-10-29 13:55:58 INFO  MemoryStore:59 - MemoryStore started with capacity 508.9 MB
2015-10-29 13:55:58 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-e740169c-fb36-42ba-861d-0dc068818d8a/httpd-5a190ddc-3a51-43fa-b393-fc04d6bd3ff8
2015-10-29 13:55:58 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:55:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:58 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49380
2015-10-29 13:55:58 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49380.
2015-10-29 13:55:58 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:55:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@7f201d6a: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:55:58 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:55:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@45399d1: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:55:58 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 13:55:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@32134389: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:55:59 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 13:55:59 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:59 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:59 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@188c74ad: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:55:59 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 13:55:59 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:59 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4044
2015-10-29 13:55:59 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4044.
2015-10-29 13:55:59 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4044
2015-10-29 13:55:59 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:55:59 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:55:59 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49381.
2015-10-29 13:55:59 INFO  NettyBlockTransferService:59 - Server created on 49381
2015-10-29 13:55:59 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:55:59 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49381 with 508.9 MB RAM, BlockManagerId(driver, localhost, 49381)
2015-10-29 13:55:59 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:55:59 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:55:59 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:56:00 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=533672755
2015-10-29 13:56:00 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 508.9 MB)
2015-10-29 13:56:00 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=533672755
2015-10-29 13:56:00 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.9 MB)
2015-10-29 13:56:00 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49381 (size: 1631.0 B, free: 508.9 MB)
2015-10-29 13:56:00 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:56:00 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:56:00 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:56:00 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:56:00 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:56:00 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 69 ms on localhost (1/1)
2015-10-29 13:56:00 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:56:00 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.085 s
2015-10-29 13:56:00 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:56:00 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:56:00 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:56:00 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:56:00 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=533672755
2015-10-29 13:56:00 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 508.9 MB)
2015-10-29 13:56:00 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=533672755
2015-10-29 13:56:00 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.9 MB)
2015-10-29 13:56:00 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49381 (size: 2.2 KB, free: 508.9 MB)
2015-10-29 13:56:00 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:56:00 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:56:00 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:56:00 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:56:00 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:56:00 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 13:56:00 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 13:56:00 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (1/1)
2015-10-29 13:56:00 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.037 s
2015-10-29 13:56:00 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.268390 s
2015-10-29 14:13:22 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49381 in memory (size: 2.2 KB, free: 508.9 MB)
2015-10-29 14:13:22 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:13:22 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49381 in memory (size: 1631.0 B, free: 508.9 MB)
2015-10-29 14:13:22 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:13:22 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:13:24 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:13:24 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:13:24 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:13:24 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:13:24 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:13:24 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:13:24 INFO  Remoting:74 - Starting remoting
2015-10-29 14:13:24 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49422]
2015-10-29 14:13:24 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49422.
2015-10-29 14:13:24 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:13:24 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:13:24 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-5650e8c1-84b1-4b34-b007-bf21840120ac
2015-10-29 14:13:24 INFO  MemoryStore:59 - MemoryStore started with capacity 492.2 MB
2015-10-29 14:13:24 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-2a4accfb-47bc-44e5-ac12-f33fe443f20f/httpd-578e0ebb-038a-4dfd-889c-250a7d91af28
2015-10-29 14:13:24 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:13:24 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:24 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49423
2015-10-29 14:13:24 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49423.
2015-10-29 14:13:25 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@414d756c: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@2edd6d12: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@196d9864: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@11be5982: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@7d4f2558: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4045
2015-10-29 14:13:25 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4045.
2015-10-29 14:13:25 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4045
2015-10-29 14:13:25 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:13:25 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:13:25 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49424.
2015-10-29 14:13:25 INFO  NettyBlockTransferService:59 - Server created on 49424
2015-10-29 14:13:25 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:13:25 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49424 with 492.2 MB RAM, BlockManagerId(driver, localhost, 49424)
2015-10-29 14:13:25 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:13:26 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:13:26 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 14:13:26 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=516119592
2015-10-29 14:13:26 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 492.2 MB)
2015-10-29 14:13:26 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=516119592
2015-10-29 14:13:26 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 492.2 MB)
2015-10-29 14:13:26 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49424 (size: 1631.0 B, free: 492.2 MB)
2015-10-29 14:13:26 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:13:26 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:13:26 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 14:13:26 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:13:26 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:13:26 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 64 ms on localhost (1/1)
2015-10-29 14:13:26 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:13:26 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.079 s
2015-10-29 14:13:26 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:13:26 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:13:26 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:13:26 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=516119592
2015-10-29 14:13:26 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 492.2 MB)
2015-10-29 14:13:26 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=516119592
2015-10-29 14:13:26 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 492.2 MB)
2015-10-29 14:13:26 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49424 (size: 2.2 KB, free: 492.2 MB)
2015-10-29 14:13:26 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:13:26 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:13:26 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:13:26 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:13:26 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:13:26 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 14:13:26 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:13:26 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.044 s
2015-10-29 14:13:26 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.318420 s
2015-10-29 14:13:27 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49424 in memory (size: 2.2 KB, free: 492.2 MB)
2015-10-29 14:13:27 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:13:27 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49424 in memory (size: 1631.0 B, free: 492.2 MB)
2015-10-29 14:13:27 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:13:27 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4042
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4045
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4043
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4044
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1bb2b8c4-ceae-4743-b558-42967987a1e8
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-82d2ff8f-fa3d-41e8-a0d7-29a86d79d100
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-e740169c-fb36-42ba-861d-0dc068818d8a
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-091374ae-5d69-49dc-88ba-bb513234b47a
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remoting shut down.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-2a4accfb-47bc-44e5-ac12-f33fe443f20f
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-47efdc31-ca72-42ae-94cd-993bd0b24d49
2015-10-29 14:14:53 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:14:53 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:14:53 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:14:53 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:14:53 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:14:54 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:14:54 INFO  Remoting:74 - Starting remoting
2015-10-29 14:14:54 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49425]
2015-10-29 14:14:54 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49425.
2015-10-29 14:14:54 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:14:54 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:14:54 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-ed16b6fa-7f21-4ab4-bf03-fd51e32bf9ce
2015-10-29 14:14:54 INFO  MemoryStore:59 - MemoryStore started with capacity 491.7 MB
2015-10-29 14:14:54 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-5422cc83-65ce-4455-9a39-a16fbdd48d0e/httpd-2f19cd6b-d505-410d-a649-67f84729c862
2015-10-29 14:14:54 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:14:54 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:14:54 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49426
2015-10-29 14:14:54 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49426.
2015-10-29 14:14:54 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:14:55 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:14:55 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 14:14:55 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 14:14:55 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 14:14:55 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:14:55 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:14:55 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49427.
2015-10-29 14:14:55 INFO  NettyBlockTransferService:59 - Server created on 49427
2015-10-29 14:14:55 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:14:55 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49427 with 491.7 MB RAM, BlockManagerId(driver, localhost, 49427)
2015-10-29 14:14:55 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:14:55 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:14:55 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 491.7 MB)
2015-10-29 14:14:56 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49427 (size: 1631.0 B, free: 491.7 MB)
2015-10-29 14:14:56 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 14:14:56 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:14:56 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 77 ms on localhost (1/1)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:14:56 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.094 s
2015-10-29 14:14:56 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:14:56 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:14:56 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:14:56 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49427 (size: 2.2 KB, free: 491.7 MB)
2015-10-29 14:14:56 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:14:56 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:14:56 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:14:56 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-29 14:14:56 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:14:56 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49427 in memory (size: 1631.0 B, free: 491.7 MB)
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 276 ms on localhost (1/1)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:14:56 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.276 s
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.605306 s
2015-10-29 14:14:56 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:14:56 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:14:56 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=6228, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=10156, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49427 (size: 2.2 KB, free: 491.7 MB)
2015-10-29 14:14:56 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:14:56 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 14:14:56 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:14:56 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 14:14:56 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1161 bytes result sent to driver
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 13 ms on localhost (1/1)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 14:14:56 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.015 s
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.028232 s
2015-10-29 14:16:25 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49427 in memory (size: 2.2 KB, free: 491.7 MB)
2015-10-29 14:16:25 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 14:16:27 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:16:27 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:16:27 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:16:27 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:16:27 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:16:27 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:16:27 INFO  Remoting:74 - Starting remoting
2015-10-29 14:16:28 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49430]
2015-10-29 14:16:28 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49430.
2015-10-29 14:16:28 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:16:28 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:16:28 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-590f63e1-fa44-48ff-9c15-4c746fe469c6
2015-10-29 14:16:28 INFO  MemoryStore:59 - MemoryStore started with capacity 512.7 MB
2015-10-29 14:16:28 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1b2e32f6-5ff3-4b71-b999-aa980eb2132e/httpd-349ed300-7e90-4ec5-ac49-7720009895cf
2015-10-29 14:16:28 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:16:28 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:16:28 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49431
2015-10-29 14:16:28 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49431.
2015-10-29 14:16:28 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:16:28 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:16:28 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:16:28 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@67d2c26: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:16:28 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 14:16:28 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:16:28 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 14:16:28 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 14:16:28 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 14:16:28 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:16:28 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:16:28 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49432.
2015-10-29 14:16:28 INFO  NettyBlockTransferService:59 - Server created on 49432
2015-10-29 14:16:28 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:16:28 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49432 with 512.7 MB RAM, BlockManagerId(driver, localhost, 49432)
2015-10-29 14:16:28 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:16:28 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:16:29 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 512.7 MB)
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49432 (size: 1631.0 B, free: 512.7 MB)
2015-10-29 14:16:29 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 14:16:29 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:16:29 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 70 ms on localhost (1/1)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:16:29 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.085 s
2015-10-29 14:16:29 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:16:29 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:16:29 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(2299) called with curMem=8215, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49432 (size: 2.2 KB, free: 512.7 MB)
2015-10-29 14:16:29 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:16:29 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:16:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:16:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 14:16:29 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:16:29 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.043 s
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.277539 s
2015-10-29 14:16:29 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:16:29 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:16:29 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10514, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14442, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49432 (size: 2.2 KB, free: 512.7 MB)
2015-10-29 14:16:29 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:16:29 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 14:16:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:16:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 14:16:29 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1161 bytes result sent to driver
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 9 ms on localhost (1/1)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 14:16:29 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.011 s
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.024504 s
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49427 in memory (size: 2.2 KB, free: 491.7 MB)
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49432 in memory (size: 2.2 KB, free: 512.7 MB)
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49432 in memory (size: 2.2 KB, free: 512.7 MB)
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49432 in memory (size: 1631.0 B, free: 512.7 MB)
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:17:30 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:17:30 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:17:30 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:17:30 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:17:30 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:17:30 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:17:31 INFO  Remoting:74 - Starting remoting
2015-10-29 14:17:31 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49433]
2015-10-29 14:17:31 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49433.
2015-10-29 14:17:31 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:17:31 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:17:31 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-02a4bc95-2e80-4cee-883d-f1a1d1cfa122
2015-10-29 14:17:31 INFO  MemoryStore:59 - MemoryStore started with capacity 508.7 MB
2015-10-29 14:17:31 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-960af11c-6380-47a2-af3d-e8daae3a2f2a/httpd-6907f847-3f4a-4685-8113-6eb638893faf
2015-10-29 14:17:31 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:17:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:17:31 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49434
2015-10-29 14:17:31 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49434.
2015-10-29 14:17:31 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:17:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:17:31 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:17:31 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@28da5226: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:17:31 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 14:17:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:17:31 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:17:31 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@7d5d53ce: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:17:31 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 14:17:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:17:31 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4042
2015-10-29 14:17:31 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4042.
2015-10-29 14:17:31 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4042
2015-10-29 14:17:31 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:17:31 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:17:31 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49435.
2015-10-29 14:17:31 INFO  NettyBlockTransferService:59 - Server created on 49435
2015-10-29 14:17:31 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:17:31 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49435 with 508.7 MB RAM, BlockManagerId(driver, localhost, 49435)
2015-10-29 14:17:31 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:17:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:17:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.7 MB)
2015-10-29 14:17:32 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49435 (size: 1631.0 B, free: 508.7 MB)
2015-10-29 14:17:32 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 14:17:32 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:17:32 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 64 ms on localhost (1/1)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:17:32 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.078 s
2015-10-29 14:17:32 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:17:32 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:17:32 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49435 (size: 2.3 KB, free: 508.7 MB)
2015-10-29 14:17:32 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:17:32 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:17:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:17:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 14:17:32 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (1/1)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.034 s
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.244011 s
2015-10-29 14:17:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:17:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:17:32 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10559, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14487, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49435 (size: 2.2 KB, free: 508.7 MB)
2015-10-29 14:17:32 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:17:32 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 14:17:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:17:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 14:17:32 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1161 bytes result sent to driver
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 7 ms on localhost (1/1)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 14:17:32 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.008 s
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.019873 s
2015-10-29 14:17:33 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49435 in memory (size: 2.2 KB, free: 508.7 MB)
2015-10-29 14:17:33 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 14:17:33 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49435 in memory (size: 2.3 KB, free: 508.7 MB)
2015-10-29 14:17:33 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:17:33 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49435 in memory (size: 1631.0 B, free: 508.7 MB)
2015-10-29 14:17:33 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:17:33 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:42:44 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:42:44 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:42:44 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:42:44 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 14:42:44 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4042
2015-10-29 14:42:44 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 14:42:44 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:42:44 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:42:44 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:42:44 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:42:44 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:42:44 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:42:44 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:42:44 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:42:44 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:42:44 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:42:44 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:42:44 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:42:44 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:42:44 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:42:44 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:42:44 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:42:44 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:42:44 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-960af11c-6380-47a2-af3d-e8daae3a2f2a
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1b2e32f6-5ff3-4b71-b999-aa980eb2132e
2015-10-29 14:42:44 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:42:44 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:42:44 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:42:44 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-5422cc83-65ce-4455-9a39-a16fbdd48d0e
2015-10-29 14:42:44 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:53:05 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:53:05 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:53:05 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:53:05 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:53:05 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:53:06 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:53:06 INFO  Remoting:74 - Starting remoting
2015-10-29 14:53:07 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50170]
2015-10-29 14:53:07 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50170.
2015-10-29 14:53:07 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:53:07 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:53:07 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-6703baef-3625-4710-b2ae-47b4687baaf2
2015-10-29 14:53:07 INFO  MemoryStore:59 - MemoryStore started with capacity 491.7 MB
2015-10-29 14:53:07 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-0fbd9d8b-0ff9-4b44-9b38-2e8d74e8d324/httpd-4fbe74f8-60e7-430e-8419-dbc248ac6f43
2015-10-29 14:53:07 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:53:07 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:53:07 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50171
2015-10-29 14:53:07 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50171.
2015-10-29 14:53:07 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:53:07 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:53:07 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 14:53:07 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 14:53:07 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 14:53:07 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:53:07 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:53:07 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50172.
2015-10-29 14:53:07 INFO  NettyBlockTransferService:59 - Server created on 50172
2015-10-29 14:53:07 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:53:07 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50172 with 491.7 MB RAM, BlockManagerId(driver, localhost, 50172)
2015-10-29 14:53:07 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:53:08 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:53:08 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 14:53:08 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=515553361
2015-10-29 14:53:08 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 491.7 MB)
2015-10-29 14:53:08 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=515553361
2015-10-29 14:53:08 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 491.7 MB)
2015-10-29 14:53:08 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50172 (size: 1631.0 B, free: 491.7 MB)
2015-10-29 14:53:08 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 14:53:08 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:53:08 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 14:53:08 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:53:08 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:53:08 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 99 ms on localhost (1/1)
2015-10-29 14:53:08 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:53:08 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.117 s
2015-10-29 14:53:08 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:53:08 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:53:08 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:53:08 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:53:08 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=515553361
2015-10-29 14:53:08 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 491.7 MB)
2015-10-29 14:53:08 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=515553361
2015-10-29 14:53:08 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 491.7 MB)
2015-10-29 14:53:08 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50172 (size: 2.3 KB, free: 491.7 MB)
2015-10-29 14:53:08 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:53:08 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:53:08 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:53:08 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:53:08 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:53:08 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 8 ms
2015-10-29 14:53:08 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50172 in memory (size: 1631.0 B, free: 491.7 MB)
2015-10-29 14:53:08 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:53:08 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 68 ms on localhost (1/1)
2015-10-29 14:53:08 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:53:08 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.068 s
2015-10-29 14:53:08 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.455435 s
2015-10-29 14:53:09 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50172 in memory (size: 2.3 KB, free: 491.7 MB)
2015-10-29 14:53:09 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:53:09 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:53:09 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:55:03 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:55:03 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:55:03 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:55:03 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:55:03 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:55:03 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:55:03 INFO  Remoting:74 - Starting remoting
2015-10-29 14:55:03 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50176]
2015-10-29 14:55:03 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50176.
2015-10-29 14:55:03 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:55:03 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:55:03 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-34bfb657-24c6-441d-9016-cf815b9aa0cf
2015-10-29 14:55:03 INFO  MemoryStore:59 - MemoryStore started with capacity 491.7 MB
2015-10-29 14:55:04 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-00dbed90-9022-4ed1-9f3f-30f756ee04b5/httpd-4f718b66-1cea-4459-9831-0d4adc79931f
2015-10-29 14:55:04 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:55:04 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:55:04 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50177
2015-10-29 14:55:04 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50177.
2015-10-29 14:55:04 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:55:04 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:55:04 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:55:04 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@33a663f7: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:55:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:55:04 WARN  QueuedThreadPool:145 - 1 threads could not be stopped
2015-10-29 14:55:04 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 14:55:04 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:55:04 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 14:55:04 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 14:55:04 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 14:55:04 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:55:04 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:55:04 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50178.
2015-10-29 14:55:04 INFO  NettyBlockTransferService:59 - Server created on 50178
2015-10-29 14:55:04 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:55:04 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50178 with 491.7 MB RAM, BlockManagerId(driver, localhost, 50178)
2015-10-29 14:55:04 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:55:04 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:55:04 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 14:55:04 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 14:55:04 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 14:55:04 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 14:55:04 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:55:04 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:55:04 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 14:55:05 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=515553361
2015-10-29 14:55:05 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 491.7 MB)
2015-10-29 14:55:05 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=515553361
2015-10-29 14:55:05 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 491.7 MB)
2015-10-29 14:55:05 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50178 (size: 1631.0 B, free: 491.7 MB)
2015-10-29 14:55:05 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:55:05 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 14:55:05 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:55:05 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 14:55:05 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:55:05 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:55:05 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 91 ms on localhost (1/1)
2015-10-29 14:55:05 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:55:05 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.106 s
2015-10-29 14:55:05 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:55:05 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:55:05 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:55:05 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:55:05 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:55:05 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:55:05 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=515553361
2015-10-29 14:55:05 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 491.7 MB)
2015-10-29 14:55:05 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=515553361
2015-10-29 14:55:05 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 491.7 MB)
2015-10-29 14:55:05 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50178 (size: 2.3 KB, free: 491.7 MB)
2015-10-29 14:55:05 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:55:05 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:55:05 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:55:05 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:55:05 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:55:05 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:55:05 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 14:55:05 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 14:55:05 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 44 ms on localhost (1/1)
2015-10-29 14:55:05 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:55:05 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.045 s
2015-10-29 14:55:05 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.312633 s
2015-10-29 14:55:05 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50178 in memory (size: 2.3 KB, free: 491.7 MB)
2015-10-29 14:55:05 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:55:05 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50178 in memory (size: 1631.0 B, free: 491.7 MB)
2015-10-29 14:55:05 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:55:05 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 15:00:50 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 15:00:50 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 15:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 15:00:51 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 15:00:51 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 15:00:51 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 15:00:51 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 15:00:51 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 15:00:51 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 15:00:51 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 15:00:51 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 15:00:51 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 15:00:51 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 15:00:51 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 15:00:51 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 15:00:51 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 15:00:51 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 15:00:51 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 15:00:51 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 15:00:51 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 15:00:51 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 15:00:51 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-0fbd9d8b-0ff9-4b44-9b38-2e8d74e8d324
2015-10-29 15:00:51 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-00dbed90-9022-4ed1-9f3f-30f756ee04b5
2015-10-29 15:01:18 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 15:01:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 15:01:19 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 15:01:19 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 15:01:19 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 15:01:20 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 15:01:20 INFO  Remoting:74 - Starting remoting
2015-10-29 15:01:20 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50189]
2015-10-29 15:01:20 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50189.
2015-10-29 15:01:20 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 15:01:20 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 15:01:20 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-00f3ffd1-3439-429a-873d-b66609394716
2015-10-29 15:01:20 INFO  MemoryStore:59 - MemoryStore started with capacity 530.0 MB
2015-10-29 15:01:20 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-9223f03d-e8c6-498a-980f-9db6ce8605d3/httpd-86b426bf-4ac1-4220-82bf-7182cd7e7aa5
2015-10-29 15:01:20 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 15:01:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 15:01:20 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50190
2015-10-29 15:01:20 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50190.
2015-10-29 15:01:20 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 15:01:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 15:01:20 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 15:01:20 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 15:01:20 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 15:01:21 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 15:01:21 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 15:01:21 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50191.
2015-10-29 15:01:21 INFO  NettyBlockTransferService:59 - Server created on 50191
2015-10-29 15:01:21 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 15:01:21 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50191 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50191)
2015-10-29 15:01:21 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 15:01:21 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 15:01:21 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 15:01:21 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 15:01:21 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 15:01:21 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 15:01:21 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 15:01:21 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 15:01:21 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 15:01:21 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=555755765
2015-10-29 15:01:21 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 15:01:21 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=555755765
2015-10-29 15:01:21 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 530.0 MB)
2015-10-29 15:01:21 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50191 (size: 1631.0 B, free: 530.0 MB)
2015-10-29 15:01:21 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 15:01:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 15:01:21 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 15:01:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 15:01:21 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 15:01:21 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 15:01:22 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 72 ms on localhost (1/1)
2015-10-29 15:01:22 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 15:01:22 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.092 s
2015-10-29 15:01:22 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 15:01:22 INFO  DAGScheduler:59 - running: Set()
2015-10-29 15:01:22 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 15:01:22 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 15:01:22 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 15:01:22 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 15:01:22 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=555755765
2015-10-29 15:01:22 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 530.0 MB)
2015-10-29 15:01:22 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=555755765
2015-10-29 15:01:22 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 530.0 MB)
2015-10-29 15:01:22 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50191 (size: 2.3 KB, free: 530.0 MB)
2015-10-29 15:01:22 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 15:01:22 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 15:01:22 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 15:01:22 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 15:01:22 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 15:01:22 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 15:01:22 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 15:01:22 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 15:01:22 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (1/1)
2015-10-29 15:01:22 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.032 s
2015-10-29 15:01:22 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 15:01:22 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.378246 s
2015-10-29 15:01:38 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50191 in memory (size: 2.3 KB, free: 530.0 MB)
2015-10-29 15:01:38 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 15:01:38 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50191 in memory (size: 1631.0 B, free: 530.0 MB)
2015-10-29 15:01:38 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 15:01:38 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 15:01:42 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 15:01:43 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 15:01:43 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 15:01:43 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 15:01:43 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 15:01:43 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 15:01:43 INFO  Remoting:74 - Starting remoting
2015-10-29 15:01:43 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50192]
2015-10-29 15:01:43 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50192.
2015-10-29 15:01:43 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 15:01:43 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 15:01:43 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-8e726c11-20c4-414d-9d6e-b871eaac8c4e
2015-10-29 15:01:43 INFO  MemoryStore:59 - MemoryStore started with capacity 509.8 MB
2015-10-29 15:01:43 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-190cf003-a7e0-4650-a9ae-6e269f83402e/httpd-a9cf7d46-909a-4705-86c3-e062fd6234dd
2015-10-29 15:01:43 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 15:01:43 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 15:01:43 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50193
2015-10-29 15:01:43 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50193.
2015-10-29 15:01:43 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 15:01:43 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 15:01:43 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 15:01:43 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@39353e56: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 15:01:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 15:01:44 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 15:01:44 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 15:01:44 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 15:01:44 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 15:01:44 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 15:01:44 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 15:01:44 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 15:01:44 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50194.
2015-10-29 15:01:44 INFO  NettyBlockTransferService:59 - Server created on 50194
2015-10-29 15:01:44 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 15:01:44 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50194 with 509.8 MB RAM, BlockManagerId(driver, localhost, 50194)
2015-10-29 15:01:44 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 15:01:44 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 15:01:44 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 15:01:44 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=534522101
2015-10-29 15:01:44 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 509.8 MB)
2015-10-29 15:01:44 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=534522101
2015-10-29 15:01:44 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 509.8 MB)
2015-10-29 15:01:44 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50194 (size: 1631.0 B, free: 509.8 MB)
2015-10-29 15:01:44 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 15:01:44 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 15:01:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 15:01:44 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 15:01:44 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 15:01:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 61 ms on localhost (1/1)
2015-10-29 15:01:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 15:01:44 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.074 s
2015-10-29 15:01:44 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 15:01:44 INFO  DAGScheduler:59 - running: Set()
2015-10-29 15:01:44 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 15:01:44 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 15:01:44 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=534522101
2015-10-29 15:01:44 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 509.8 MB)
2015-10-29 15:01:44 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=534522101
2015-10-29 15:01:44 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 509.7 MB)
2015-10-29 15:01:44 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50194 (size: 2.3 KB, free: 509.8 MB)
2015-10-29 15:01:44 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 15:01:44 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 15:01:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 15:01:44 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 15:01:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 15:01:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 15:01:44 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 15:01:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (1/1)
2015-10-29 15:01:44 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.032 s
2015-10-29 15:01:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 15:01:44 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.244189 s
2015-10-29 15:02:33 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50194 in memory (size: 2.3 KB, free: 509.8 MB)
2015-10-29 15:02:33 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 15:02:33 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50194 in memory (size: 1631.0 B, free: 509.8 MB)
2015-10-29 15:02:33 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 15:02:34 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 15:19:00 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 15:19:00 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 15:19:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 15:19:00 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 15:19:00 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 15:19:00 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 15:19:00 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 15:19:00 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 15:19:00 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 15:19:00 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 15:19:00 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 15:19:00 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 15:19:00 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 15:19:00 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 15:19:00 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 15:19:00 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 15:19:00 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 15:19:00 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 15:19:00 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 15:19:00 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 15:19:00 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 15:19:00 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-190cf003-a7e0-4650-a9ae-6e269f83402e
2015-10-29 15:19:00 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-9223f03d-e8c6-498a-980f-9db6ce8605d3
2015-10-29 15:19:14 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 15:19:14 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 15:19:15 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 15:19:15 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 15:19:15 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 15:19:15 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 15:19:15 INFO  Remoting:74 - Starting remoting
2015-10-29 15:19:15 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50266]
2015-10-29 15:19:15 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50266.
2015-10-29 15:19:16 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 15:19:16 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 15:19:16 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-67f77354-b5cd-425c-865d-793e8716b190
2015-10-29 15:19:16 INFO  MemoryStore:59 - MemoryStore started with capacity 530.0 MB
2015-10-29 15:19:16 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-902c6987-6c62-47c9-9b79-82f9617f8e63/httpd-8e1d7806-4a65-48ce-a49e-4a2a85f4804d
2015-10-29 15:19:16 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 15:19:16 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 15:19:16 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50267
2015-10-29 15:19:16 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50267.
2015-10-29 15:19:16 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 15:19:16 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 15:19:16 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 15:19:16 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 15:19:16 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 15:19:16 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 15:19:16 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 15:19:16 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50268.
2015-10-29 15:19:16 INFO  NettyBlockTransferService:59 - Server created on 50268
2015-10-29 15:19:16 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 15:19:16 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50268 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50268)
2015-10-29 15:19:16 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 15:19:17 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 15:19:17 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 15:19:17 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=555755765
2015-10-29 15:19:17 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 15:19:17 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=555755765
2015-10-29 15:19:17 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 530.0 MB)
2015-10-29 15:19:17 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50268 (size: 1631.0 B, free: 530.0 MB)
2015-10-29 15:19:17 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 15:19:17 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 15:19:17 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 15:19:17 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 15:19:17 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 15:19:17 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 74 ms on localhost (1/1)
2015-10-29 15:19:17 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 15:19:17 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.090 s
2015-10-29 15:19:17 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 15:19:17 INFO  DAGScheduler:59 - running: Set()
2015-10-29 15:19:17 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 15:19:17 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 15:19:17 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=555755765
2015-10-29 15:19:17 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 530.0 MB)
2015-10-29 15:19:17 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=555755765
2015-10-29 15:19:17 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 530.0 MB)
2015-10-29 15:19:17 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50268 (size: 2.3 KB, free: 530.0 MB)
2015-10-29 15:19:17 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 15:19:17 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 15:19:17 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 15:19:17 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 15:19:17 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 15:19:17 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 15:19:17 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 15:19:17 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 15:19:17 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 15:19:17 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.043 s
2015-10-29 15:19:17 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.343900 s
2015-10-29 15:21:01 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50268 in memory (size: 2.3 KB, free: 530.0 MB)
2015-10-29 15:21:01 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 15:21:01 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50268 in memory (size: 1631.0 B, free: 530.0 MB)
2015-10-29 15:21:01 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 15:21:01 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:03:12 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:03:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:03:12 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 16:03:12 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:03:12 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 16:03:12 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 16:03:12 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 16:03:12 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 16:03:12 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 16:03:12 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 16:03:12 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 16:03:12 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-902c6987-6c62-47c9-9b79-82f9617f8e63
2015-10-29 16:04:41 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:04:41 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:04:41 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:04:41 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:04:41 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:04:42 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:04:42 INFO  Remoting:74 - Starting remoting
2015-10-29 16:04:42 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50581]
2015-10-29 16:04:42 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50581.
2015-10-29 16:04:42 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:04:42 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:04:42 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-7600b491-90fc-470b-93e3-12aef43baf19
2015-10-29 16:04:42 INFO  MemoryStore:59 - MemoryStore started with capacity 504.6 MB
2015-10-29 16:04:42 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-9f6d6908-cd04-442c-b219-fa67f556f690/httpd-cb333545-1dcc-4d29-a2a3-c0e61b207694
2015-10-29 16:04:42 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:04:42 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:04:42 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50582
2015-10-29 16:04:42 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50582.
2015-10-29 16:04:43 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:04:43 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:04:43 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 16:04:43 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 16:04:43 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 16:04:43 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:04:43 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:04:43 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50583.
2015-10-29 16:04:43 INFO  NettyBlockTransferService:59 - Server created on 50583
2015-10-29 16:04:43 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:04:43 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50583 with 504.6 MB RAM, BlockManagerId(driver, localhost, 50583)
2015-10-29 16:04:43 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:04:43 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:04:43 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:04:44 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=529142906
2015-10-29 16:04:44 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 504.6 MB)
2015-10-29 16:04:44 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=529142906
2015-10-29 16:04:44 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 504.6 MB)
2015-10-29 16:04:44 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50583 (size: 1631.0 B, free: 504.6 MB)
2015-10-29 16:04:44 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:04:44 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:04:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 16:04:44 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:04:44 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:04:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 128 ms on localhost (1/1)
2015-10-29 16:04:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:04:44 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.172 s
2015-10-29 16:04:44 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:04:44 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:04:44 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:04:44 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:04:44 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=529142906
2015-10-29 16:04:44 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 504.6 MB)
2015-10-29 16:04:44 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=529142906
2015-10-29 16:04:44 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 504.6 MB)
2015-10-29 16:04:44 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50583 (size: 2.3 KB, free: 504.6 MB)
2015-10-29 16:04:44 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:04:44 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:04:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:04:44 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:04:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:04:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-29 16:04:44 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:04:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 45 ms on localhost (1/1)
2015-10-29 16:04:44 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.049 s
2015-10-29 16:04:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:04:44 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.557280 s
2015-10-29 16:06:02 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50583 in memory (size: 2.3 KB, free: 504.6 MB)
2015-10-29 16:06:02 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:06:03 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:06:04 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:06:04 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:06:04 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:06:04 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:06:04 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:06:04 INFO  Remoting:74 - Starting remoting
2015-10-29 16:06:04 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50587]
2015-10-29 16:06:04 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50587.
2015-10-29 16:06:04 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:06:04 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:06:04 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-773658cf-452b-494a-a437-57fbd1b4dc76
2015-10-29 16:06:04 INFO  MemoryStore:59 - MemoryStore started with capacity 509.8 MB
2015-10-29 16:06:04 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-9d1eb5bf-aed9-4214-9530-26da90b87407/httpd-40ca42e2-0ca7-40ec-a8fe-c825e8cb9340
2015-10-29 16:06:04 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:06:05 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:06:05 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50588
2015-10-29 16:06:05 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50588.
2015-10-29 16:06:05 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:06:05 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:06:05 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:06:05 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@3a564967: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:06:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:06:05 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:06:05 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:06:05 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 16:06:05 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 16:06:05 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 16:06:05 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:06:05 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:06:05 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50589.
2015-10-29 16:06:05 INFO  NettyBlockTransferService:59 - Server created on 50589
2015-10-29 16:06:05 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:06:05 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50589 with 509.8 MB RAM, BlockManagerId(driver, localhost, 50589)
2015-10-29 16:06:05 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:06:06 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:06:06 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:06:06 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=534522101
2015-10-29 16:06:06 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 509.8 MB)
2015-10-29 16:06:06 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=534522101
2015-10-29 16:06:06 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 509.8 MB)
2015-10-29 16:06:06 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50589 (size: 1631.0 B, free: 509.8 MB)
2015-10-29 16:06:06 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:06:06 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:06:06 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 16:06:06 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:06:06 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:06:06 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 75 ms on localhost (1/1)
2015-10-29 16:06:06 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:06:06 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.093 s
2015-10-29 16:06:06 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:06:06 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:06:06 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:06:06 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:06:06 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=534522101
2015-10-29 16:06:06 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 509.8 MB)
2015-10-29 16:06:06 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=534522101
2015-10-29 16:06:06 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 509.7 MB)
2015-10-29 16:06:06 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50589 (size: 2.3 KB, free: 509.8 MB)
2015-10-29 16:06:06 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:06:06 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:06:06 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:06:06 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:06:06 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:06:06 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 16:06:06 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:06:06 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 43 ms on localhost (1/1)
2015-10-29 16:06:06 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.044 s
2015-10-29 16:06:06 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:06:06 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.316314 s
2015-10-29 16:06:06 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50589 in memory (size: 1631.0 B, free: 509.8 MB)
2015-10-29 16:06:07 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50583 in memory (size: 1631.0 B, free: 504.6 MB)
2015-10-29 16:06:07 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50589 in memory (size: 2.3 KB, free: 509.8 MB)
2015-10-29 16:06:07 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:06:07 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:06:07 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:06:07 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:06:07 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:10:16 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:10:16 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:10:16 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:10:16 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:10:16 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:10:17 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:10:17 INFO  Remoting:74 - Starting remoting
2015-10-29 16:10:17 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50595]
2015-10-29 16:10:17 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50595.
2015-10-29 16:10:17 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:10:17 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:10:17 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-407279d4-0e25-4f23-a7c0-26a2a0546d1c
2015-10-29 16:10:17 INFO  MemoryStore:59 - MemoryStore started with capacity 494.9 MB
2015-10-29 16:10:17 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-91cde53d-9451-4177-a5a3-f79237837a40/httpd-5c53b21c-12d7-47b0-b9c0-3c098c83bc34
2015-10-29 16:10:17 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:10:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:10:17 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50596
2015-10-29 16:10:17 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50596.
2015-10-29 16:10:17 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:10:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:10:17 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:10:17 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@14b98796: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:10:17 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:10:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:10:17 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:10:17 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@5cfccae3: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:10:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:10:17 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:10:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:10:17 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4042
2015-10-29 16:10:17 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4042.
2015-10-29 16:10:17 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4042
2015-10-29 16:10:18 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:10:18 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:10:18 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50597.
2015-10-29 16:10:18 INFO  NettyBlockTransferService:59 - Server created on 50597
2015-10-29 16:10:18 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:10:18 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50597 with 494.9 MB RAM, BlockManagerId(driver, localhost, 50597)
2015-10-29 16:10:18 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:10:18 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:10:18 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:10:18 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=518950748
2015-10-29 16:10:18 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 494.9 MB)
2015-10-29 16:10:18 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=518950748
2015-10-29 16:10:18 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 494.9 MB)
2015-10-29 16:10:18 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50597 (size: 1631.0 B, free: 494.9 MB)
2015-10-29 16:10:18 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:10:18 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:10:18 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 16:10:18 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:10:18 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:10:18 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 75 ms on localhost (1/1)
2015-10-29 16:10:18 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:10:18 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.092 s
2015-10-29 16:10:18 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:10:18 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:10:18 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:10:18 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:10:18 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=518950748
2015-10-29 16:10:18 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 494.9 MB)
2015-10-29 16:10:18 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=518950748
2015-10-29 16:10:18 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 494.9 MB)
2015-10-29 16:10:18 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50597 (size: 2.3 KB, free: 494.9 MB)
2015-10-29 16:10:18 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:10:18 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:10:18 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:10:18 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:10:18 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:10:18 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 16:10:18 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:10:18 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 43 ms on localhost (1/1)
2015-10-29 16:10:18 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.044 s
2015-10-29 16:10:18 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:10:18 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.311446 s
2015-10-29 16:18:31 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:18:31 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:18:31 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:18:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:18:31 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 16:18:31 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4042
2015-10-29 16:18:31 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 16:18:31 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:18:31 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:18:31 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:18:31 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 16:18:31 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 16:18:31 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 16:18:31 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 16:18:31 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 16:18:31 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 16:18:31 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 16:18:31 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 16:18:31 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 16:18:31 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 16:18:31 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 16:18:31 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 16:18:31 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 16:18:31 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 16:18:31 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 16:18:31 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 16:18:31 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 16:18:31 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 16:18:31 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 16:18:31 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-9f6d6908-cd04-442c-b219-fa67f556f690
2015-10-29 16:18:31 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 16:18:31 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 16:18:31 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-9d1eb5bf-aed9-4214-9530-26da90b87407
2015-10-29 16:18:31 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-91cde53d-9451-4177-a5a3-f79237837a40
2015-10-29 16:25:19 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:25:20 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:25:20 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:25:20 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:25:20 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:25:20 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:25:20 INFO  Remoting:74 - Starting remoting
2015-10-29 16:25:20 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50708]
2015-10-29 16:25:20 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50708.
2015-10-29 16:25:21 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:25:21 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:25:21 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-23d5b679-2d82-4afb-b00a-08dcb3b49624
2015-10-29 16:25:21 INFO  MemoryStore:59 - MemoryStore started with capacity 530.0 MB
2015-10-29 16:25:21 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-f59dd0a5-abe1-4542-a2fa-b045d53d57c9/httpd-7789b414-3448-4aaa-8e81-cc0edda72408
2015-10-29 16:25:21 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:25:21 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:25:21 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50709
2015-10-29 16:25:21 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50709.
2015-10-29 16:25:21 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:25:21 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:25:21 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 16:25:21 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 16:25:21 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 16:25:21 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:25:21 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:25:22 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50710.
2015-10-29 16:25:22 INFO  NettyBlockTransferService:59 - Server created on 50710
2015-10-29 16:25:22 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:25:22 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50710 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50710)
2015-10-29 16:25:22 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:25:22 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:25:22 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:25:22 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:25:22 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:25:22 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:25:22 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:25:22 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:25:22 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:25:23 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=555755765
2015-10-29 16:25:23 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 16:25:23 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=555755765
2015-10-29 16:25:23 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 530.0 MB)
2015-10-29 16:25:23 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50710 (size: 1629.0 B, free: 530.0 MB)
2015-10-29 16:25:23 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:25:23 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:25:23 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:25:23 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 16:25:23 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:25:23 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:25:23 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 92 ms on localhost (1/1)
2015-10-29 16:25:23 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:25:23 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.112 s
2015-10-29 16:25:23 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:25:23 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:25:23 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:25:23 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:25:23 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:25:23 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:25:23 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4285, maxMem=555755765
2015-10-29 16:25:23 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 530.0 MB)
2015-10-29 16:25:23 INFO  MemoryStore:59 - ensureFreeSpace(2304) called with curMem=8237, maxMem=555755765
2015-10-29 16:25:23 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 530.0 MB)
2015-10-29 16:25:23 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50710 (size: 2.3 KB, free: 530.0 MB)
2015-10-29 16:25:23 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:25:23 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:25:23 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:25:23 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:25:23 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:25:23 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:25:23 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 9 ms
2015-10-29 16:25:23 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:25:23 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 55 ms on localhost (1/1)
2015-10-29 16:25:23 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.057 s
2015-10-29 16:25:23 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:25:23 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.420547 s
2015-10-29 16:25:23 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50710 in memory (size: 2.3 KB, free: 530.0 MB)
2015-10-29 16:25:23 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:25:23 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50710 in memory (size: 1629.0 B, free: 530.0 MB)
2015-10-29 16:25:23 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:25:23 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:26:11 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:26:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:26:11 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:26:11 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:26:11 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:26:11 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:26:11 INFO  Remoting:74 - Starting remoting
2015-10-29 16:26:11 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50715]
2015-10-29 16:26:11 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50715.
2015-10-29 16:26:11 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:26:11 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:26:11 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-56c55b4c-1d58-49a4-8e80-a6531aa0f011
2015-10-29 16:26:11 INFO  MemoryStore:59 - MemoryStore started with capacity 506.3 MB
2015-10-29 16:26:11 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-3635dc7c-aa49-4665-8ea2-9b73c0a40e1d/httpd-64a109a7-2504-40f0-b00f-aea1ab4ee765
2015-10-29 16:26:11 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:26:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:26:12 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50716
2015-10-29 16:26:12 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50716.
2015-10-29 16:26:12 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:26:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:26:12 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:26:12 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@6034a980: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:26:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:26:12 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:26:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:26:12 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 16:26:12 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 16:26:12 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 16:26:12 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:26:12 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:26:12 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50717.
2015-10-29 16:26:12 INFO  NettyBlockTransferService:59 - Server created on 50717
2015-10-29 16:26:12 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:26:12 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50717 with 506.3 MB RAM, BlockManagerId(driver, localhost, 50717)
2015-10-29 16:26:12 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:26:13 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:26:13 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:26:13 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=530841600
2015-10-29 16:26:13 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 506.2 MB)
2015-10-29 16:26:13 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=530841600
2015-10-29 16:26:13 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 506.2 MB)
2015-10-29 16:26:13 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50717 (size: 1629.0 B, free: 506.2 MB)
2015-10-29 16:26:13 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:26:13 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:26:13 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 16:26:13 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:26:13 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:26:13 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 71 ms on localhost (1/1)
2015-10-29 16:26:13 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:26:13 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.088 s
2015-10-29 16:26:13 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:26:13 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:26:13 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:26:13 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:26:13 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4285, maxMem=530841600
2015-10-29 16:26:13 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 506.2 MB)
2015-10-29 16:26:13 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=8213, maxMem=530841600
2015-10-29 16:26:13 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 506.2 MB)
2015-10-29 16:26:13 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50717 (size: 2.2 KB, free: 506.2 MB)
2015-10-29 16:26:13 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:26:13 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:26:13 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:26:13 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:26:13 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:26:13 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 16:26:13 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1878 bytes result sent to driver
2015-10-29 16:26:13 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 49 ms on localhost (1/1)
2015-10-29 16:26:13 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:26:13 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.049 s
2015-10-29 16:26:13 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.295333 s
2015-10-29 16:26:30 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50717 in memory (size: 2.2 KB, free: 506.2 MB)
2015-10-29 16:26:30 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:26:30 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50717 in memory (size: 1629.0 B, free: 506.3 MB)
2015-10-29 16:26:30 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:26:30 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:26:32 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:26:32 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:26:32 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:26:32 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:26:32 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:26:32 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:26:32 INFO  Remoting:74 - Starting remoting
2015-10-29 16:26:32 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50718]
2015-10-29 16:26:32 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50718.
2015-10-29 16:26:32 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:26:32 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:26:33 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-6bd6da1b-adfc-4121-88f3-dd5edd2bc986
2015-10-29 16:26:33 INFO  MemoryStore:59 - MemoryStore started with capacity 501.4 MB
2015-10-29 16:26:33 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-4c2a98cb-0d8c-4b51-b7f8-757089456508/httpd-9e9b801c-8c8f-4726-bb6b-fbf784fddfdd
2015-10-29 16:26:33 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:26:33 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:26:33 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50719
2015-10-29 16:26:33 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50719.
2015-10-29 16:26:33 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:26:33 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:26:33 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:26:33 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@4d73b3ea: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:26:33 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:26:33 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:26:33 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:26:33 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@4fe1ca21: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:26:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:26:33 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:26:33 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:26:33 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4042
2015-10-29 16:26:33 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4042.
2015-10-29 16:26:33 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4042
2015-10-29 16:26:33 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:26:33 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:26:33 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50720.
2015-10-29 16:26:33 INFO  NettyBlockTransferService:59 - Server created on 50720
2015-10-29 16:26:33 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:26:33 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50720 with 501.4 MB RAM, BlockManagerId(driver, localhost, 50720)
2015-10-29 16:26:33 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:26:34 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:26:34 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:26:34 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=525745520
2015-10-29 16:26:34 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 501.4 MB)
2015-10-29 16:26:34 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=525745520
2015-10-29 16:26:34 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 501.4 MB)
2015-10-29 16:26:34 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50720 (size: 1629.0 B, free: 501.4 MB)
2015-10-29 16:26:34 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:26:34 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:26:34 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 16:26:34 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:26:34 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:26:34 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 68 ms on localhost (1/1)
2015-10-29 16:26:34 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:26:34 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.085 s
2015-10-29 16:26:34 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:26:34 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:26:34 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:26:34 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:26:34 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4285, maxMem=525745520
2015-10-29 16:26:34 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 501.4 MB)
2015-10-29 16:26:34 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=8213, maxMem=525745520
2015-10-29 16:26:34 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 501.4 MB)
2015-10-29 16:26:34 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50720 (size: 2.2 KB, free: 501.4 MB)
2015-10-29 16:26:34 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:26:34 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:26:34 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:26:34 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:26:34 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:26:34 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 16:26:34 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1878 bytes result sent to driver
2015-10-29 16:26:34 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 16:26:34 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:26:34 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.043 s
2015-10-29 16:26:34 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.286946 s
2015-10-29 16:26:35 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50720 in memory (size: 2.2 KB, free: 501.4 MB)
2015-10-29 16:26:35 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:26:35 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50720 in memory (size: 1629.0 B, free: 501.4 MB)
2015-10-29 16:26:35 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:26:35 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:27:16 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:27:16 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:27:16 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:27:16 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:27:16 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:27:17 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:27:17 INFO  Remoting:74 - Starting remoting
2015-10-29 16:27:17 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50722]
2015-10-29 16:27:17 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50722.
2015-10-29 16:27:17 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:27:17 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:27:17 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-0cf87f32-9fbf-49d1-908f-78bdb8e6ed59
2015-10-29 16:27:17 INFO  MemoryStore:59 - MemoryStore started with capacity 502.5 MB
2015-10-29 16:27:17 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-b30dfd32-65b0-4c7a-9907-f2b9baf4b008/httpd-73abb273-c081-4660-ba97-93a095010033
2015-10-29 16:27:17 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:27:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:27:17 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50723
2015-10-29 16:27:17 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50723.
2015-10-29 16:27:17 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:27:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:27:17 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:27:17 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@103a7e5e: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:27:17 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:27:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:27:17 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:27:17 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@674772b4: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:27:17 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:27:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:27:17 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:27:17 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@3dcc9e3a: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:27:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:27:17 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:27:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:27:17 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4043
2015-10-29 16:27:17 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4043.
2015-10-29 16:27:17 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4043
2015-10-29 16:27:17 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:27:17 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:27:18 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50724.
2015-10-29 16:27:18 INFO  NettyBlockTransferService:59 - Server created on 50724
2015-10-29 16:27:18 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:27:18 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50724 with 502.5 MB RAM, BlockManagerId(driver, localhost, 50724)
2015-10-29 16:27:18 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:27:18 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:27:18 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:27:18 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=526877982
2015-10-29 16:27:18 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 502.5 MB)
2015-10-29 16:27:18 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=526877982
2015-10-29 16:27:18 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 502.5 MB)
2015-10-29 16:27:18 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50724 (size: 1629.0 B, free: 502.5 MB)
2015-10-29 16:27:18 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:27:18 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:27:18 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2566 bytes)
2015-10-29 16:27:18 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:27:18 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:27:18 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 74 ms on localhost (1/1)
2015-10-29 16:27:18 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:27:18 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.090 s
2015-10-29 16:27:18 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:27:18 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:27:18 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:27:18 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:27:18 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4285, maxMem=526877982
2015-10-29 16:27:18 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 502.5 MB)
2015-10-29 16:27:18 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=8213, maxMem=526877982
2015-10-29 16:27:18 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 502.5 MB)
2015-10-29 16:27:18 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50724 (size: 2.2 KB, free: 502.5 MB)
2015-10-29 16:27:18 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:27:18 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:27:18 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:27:18 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:27:18 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:27:19 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:27:19 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 7 ms
2015-10-29 16:27:19 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1878 bytes result sent to driver
2015-10-29 16:27:19 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 45 ms on localhost (1/1)
2015-10-29 16:27:19 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.045 s
2015-10-29 16:27:19 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:27:19 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.289823 s
2015-10-29 16:28:55 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50724 in memory (size: 2.2 KB, free: 502.5 MB)
2015-10-29 16:28:55 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:28:55 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50724 in memory (size: 1629.0 B, free: 502.5 MB)
2015-10-29 16:28:55 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:28:55 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:28:57 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:28:57 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:28:57 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:28:57 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:28:57 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:28:57 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:28:57 INFO  Remoting:74 - Starting remoting
2015-10-29 16:28:58 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50727]
2015-10-29 16:28:58 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50727.
2015-10-29 16:28:58 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:28:58 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:28:58 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-f1d4a395-fd00-439e-ac20-1b5bd90ad17b
2015-10-29 16:28:58 INFO  MemoryStore:59 - MemoryStore started with capacity 505.7 MB
2015-10-29 16:28:58 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-09940077-4dd6-493b-ba00-ea78e3f9b929/httpd-a0869617-80bc-400d-981c-7e176d4cfcb3
2015-10-29 16:28:58 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:28:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:28:58 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50728
2015-10-29 16:28:58 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50728.
2015-10-29 16:28:58 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:28:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:28:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:28:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@54e94dd3: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:28:58 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:28:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:28:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:28:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@1f06e186: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:28:58 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:28:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:28:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:28:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@33feb30e: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:28:58 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:28:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:28:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:28:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@53cb9ffb: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:28:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:28:58 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 16:28:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:28:58 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4044
2015-10-29 16:28:58 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4044.
2015-10-29 16:28:58 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4044
2015-10-29 16:28:58 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:28:58 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:28:58 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50729.
2015-10-29 16:28:58 INFO  NettyBlockTransferService:59 - Server created on 50729
2015-10-29 16:28:58 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:28:58 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50729 with 505.7 MB RAM, BlockManagerId(driver, localhost, 50729)
2015-10-29 16:28:58 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:28:59 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:28:59 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:28:59 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=530275368
2015-10-29 16:28:59 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 505.7 MB)
2015-10-29 16:28:59 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=530275368
2015-10-29 16:28:59 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 505.7 MB)
2015-10-29 16:28:59 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50729 (size: 1629.0 B, free: 505.7 MB)
2015-10-29 16:28:59 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:28:59 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:28:59 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2565 bytes)
2015-10-29 16:28:59 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:28:59 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:28:59 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 78 ms on localhost (1/1)
2015-10-29 16:28:59 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:28:59 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.097 s
2015-10-29 16:28:59 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:28:59 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:28:59 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:28:59 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:28:59 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4285, maxMem=530275368
2015-10-29 16:28:59 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 505.7 MB)
2015-10-29 16:28:59 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=8213, maxMem=530275368
2015-10-29 16:28:59 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 505.7 MB)
2015-10-29 16:28:59 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50729 (size: 2.2 KB, free: 505.7 MB)
2015-10-29 16:28:59 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:28:59 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:28:59 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:28:59 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:28:59 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:28:59 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 7 ms
2015-10-29 16:28:59 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1877 bytes result sent to driver
2015-10-29 16:28:59 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 49 ms on localhost (1/1)
2015-10-29 16:28:59 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.050 s
2015-10-29 16:28:59 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:28:59 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.322704 s
2015-10-29 16:29:00 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50729 in memory (size: 2.2 KB, free: 505.7 MB)
2015-10-29 16:29:00 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:29:00 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50729 in memory (size: 1629.0 B, free: 505.7 MB)
2015-10-29 16:29:00 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:29:00 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:29:18 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:29:18 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:29:18 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:29:18 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:29:18 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:29:19 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:29:19 INFO  Remoting:74 - Starting remoting
2015-10-29 16:29:19 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50732]
2015-10-29 16:29:19 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50732.
2015-10-29 16:29:19 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:29:19 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:29:19 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-80531605-b72a-414b-993b-74b6d5695a18
2015-10-29 16:29:19 INFO  MemoryStore:59 - MemoryStore started with capacity 509.2 MB
2015-10-29 16:29:19 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-50cb25e7-ff58-4e92-b384-7599b1165a12/httpd-c15d6710-86eb-4954-a0f2-ceaab0e0c18f
2015-10-29 16:29:19 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:29:19 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:19 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50733
2015-10-29 16:29:19 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50733.
2015-10-29 16:29:19 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:29:19 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:19 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:19 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@e0fd131: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:19 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:29:19 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:19 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:19 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@38eaee37: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:19 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:29:19 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:19 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:19 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@2ac6e8e1: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:19 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:29:19 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:19 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:19 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@78833d56: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:19 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:20 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 16:29:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:20 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:20 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@4ca8728b: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:20 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2015-10-29 16:29:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:20 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4045
2015-10-29 16:29:20 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4045.
2015-10-29 16:29:20 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4045
2015-10-29 16:29:20 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:29:20 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:29:20 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50734.
2015-10-29 16:29:20 INFO  NettyBlockTransferService:59 - Server created on 50734
2015-10-29 16:29:20 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:29:20 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50734 with 509.2 MB RAM, BlockManagerId(driver, localhost, 50734)
2015-10-29 16:29:20 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:29:21 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:29:21 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:29:21 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=533955870
2015-10-29 16:29:21 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 509.2 MB)
2015-10-29 16:29:21 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=533955870
2015-10-29 16:29:21 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 509.2 MB)
2015-10-29 16:29:21 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50734 (size: 1629.0 B, free: 509.2 MB)
2015-10-29 16:29:21 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:29:21 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:29:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2565 bytes)
2015-10-29 16:29:21 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:29:21 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:29:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 99 ms on localhost (1/1)
2015-10-29 16:29:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:29:21 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.118 s
2015-10-29 16:29:21 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:29:21 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:29:21 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:29:21 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:29:21 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4285, maxMem=533955870
2015-10-29 16:29:21 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 509.2 MB)
2015-10-29 16:29:21 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=8213, maxMem=533955870
2015-10-29 16:29:21 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 509.2 MB)
2015-10-29 16:29:21 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50734 (size: 2.2 KB, free: 509.2 MB)
2015-10-29 16:29:21 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:29:21 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:29:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:29:21 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:29:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:29:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-29 16:29:21 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1877 bytes result sent to driver
2015-10-29 16:29:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 50 ms on localhost (1/1)
2015-10-29 16:29:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:29:21 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.050 s
2015-10-29 16:29:21 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.368485 s
2015-10-29 16:29:36 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50734 in memory (size: 2.2 KB, free: 509.2 MB)
2015-10-29 16:29:36 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:29:36 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50734 in memory (size: 1629.0 B, free: 509.2 MB)
2015-10-29 16:29:36 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:29:36 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:29:38 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:29:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:29:38 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:29:38 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:29:38 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:29:38 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:29:38 INFO  Remoting:74 - Starting remoting
2015-10-29 16:29:38 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50735]
2015-10-29 16:29:38 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50735.
2015-10-29 16:29:38 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:29:38 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:29:38 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-1e2868a2-c916-48ec-8eff-58859f33dbbf
2015-10-29 16:29:38 INFO  MemoryStore:59 - MemoryStore started with capacity 508.7 MB
2015-10-29 16:29:39 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1ea87d99-0ffc-4d0c-8391-ee14346b6d57/httpd-b79e3037-15e6-4047-83b3-ffbc449c3dc4
2015-10-29 16:29:39 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:29:39 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:39 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50736
2015-10-29 16:29:39 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50736.
2015-10-29 16:29:39 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:29:39 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@8cc9a94: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:39 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:29:39 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@2cac37e: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:39 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:29:39 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@3ccd00b5: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:39 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:29:39 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@58036657: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:39 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 16:29:39 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@77dba66: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:39 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2015-10-29 16:29:39 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4045: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@7c722cc1: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:29:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:29:39 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
2015-10-29 16:29:39 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:29:39 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4046
2015-10-29 16:29:39 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4046.
2015-10-29 16:29:39 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4046
2015-10-29 16:29:39 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:29:39 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:29:39 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50737.
2015-10-29 16:29:39 INFO  NettyBlockTransferService:59 - Server created on 50737
2015-10-29 16:29:39 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:29:39 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50737 with 508.7 MB RAM, BlockManagerId(driver, localhost, 50737)
2015-10-29 16:29:39 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:29:40 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:29:40 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:29:40 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:29:40 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:29:40 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:29:40 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:29:40 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:29:40 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:30:49 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:30:49 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:30:49 WARN  ShutdownHookManager:56 - ShutdownHook '$anon$2' failed, java.lang.OutOfMemoryError: Metaspace
java.lang.OutOfMemoryError: Metaspace
2015-10-29 16:30:50 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:30:50 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:30:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:30:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:31:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:31:00 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:31:01 WARN  ShutdownHookManager:56 - ShutdownHook '$anon$2' failed, java.lang.OutOfMemoryError: Metaspace
java.lang.OutOfMemoryError: Metaspace
2015-10-29 16:31:02 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:31:02 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:31:03 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:31:03 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:31:03 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:31:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:31:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:31:08 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:31:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:31:09 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:31:09 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:31:10 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:31:09 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:31:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:31:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:31:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:31:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:31:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:31:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:31:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:31:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:31:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:31:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:31:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:31:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:31:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:31:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:31:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:31:22 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:31:22 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:31:22 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:31:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:31:24 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:31:24 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:31:22 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:31:24 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:31:24 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:31:24 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:31:24 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:31:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:31:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:31:24 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:31:24 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:31:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:31:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:31:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:31:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:31:29 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:31:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:31:30 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:31:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:31:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:31:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:31:32 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:31:34 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:31:38 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:31:33 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4042
2015-10-29 16:31:39 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:31:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:31:43 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 16:31:47 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:31:47 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:31:47 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:31:47 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:31:47 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:31:49 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:31:49 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 16:31:49 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:31:50 WARN  ShutdownHookManager:56 - ShutdownHook '$anon$2' failed, java.lang.OutOfMemoryError: Metaspace
java.lang.OutOfMemoryError: Metaspace
2015-10-29 16:31:52 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:32:01 WARN  ShutdownHookManager:56 - ShutdownHook '$anon$2' failed, java.lang.OutOfMemoryError: Metaspace
java.lang.OutOfMemoryError: Metaspace
2015-10-29 16:32:47 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:32:47 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:32:47 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:32:47 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:32:47 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:32:48 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:32:48 INFO  Remoting:74 - Starting remoting
2015-10-29 16:32:48 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50744]
2015-10-29 16:32:48 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50744.
2015-10-29 16:32:48 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:32:48 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:32:48 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-4e9191ef-3613-4fa5-99cd-778aa3ba32fa
2015-10-29 16:32:48 INFO  MemoryStore:59 - MemoryStore started with capacity 530.0 MB
2015-10-29 16:32:48 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-7d5a5881-ab49-40d9-89d6-ce0c31a971b3/httpd-3e34bf86-e25f-452d-8562-0cb0e234966a
2015-10-29 16:32:48 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:32:48 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:32:48 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50745
2015-10-29 16:32:48 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50745.
2015-10-29 16:32:48 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:32:49 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:32:49 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 16:32:49 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 16:32:49 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 16:32:49 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:32:49 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:32:49 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50746.
2015-10-29 16:32:49 INFO  NettyBlockTransferService:59 - Server created on 50746
2015-10-29 16:32:49 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:32:49 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50746 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50746)
2015-10-29 16:32:49 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:32:50 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:32:50 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:32:50 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=555755765
2015-10-29 16:32:50 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 16:32:50 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=555755765
2015-10-29 16:32:50 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 530.0 MB)
2015-10-29 16:32:50 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50746 (size: 1629.0 B, free: 530.0 MB)
2015-10-29 16:32:50 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:32:50 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:32:50 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2565 bytes)
2015-10-29 16:32:50 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:32:50 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:32:50 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 79 ms on localhost (1/1)
2015-10-29 16:32:50 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:32:50 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.096 s
2015-10-29 16:32:50 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:32:50 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:32:50 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:32:50 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:32:50 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4285, maxMem=555755765
2015-10-29 16:32:50 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 530.0 MB)
2015-10-29 16:32:50 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=8213, maxMem=555755765
2015-10-29 16:32:50 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 530.0 MB)
2015-10-29 16:32:50 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50746 (size: 2.2 KB, free: 530.0 MB)
2015-10-29 16:32:50 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:32:50 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:32:50 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:32:50 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:32:50 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:32:50 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 16:32:50 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1877 bytes result sent to driver
2015-10-29 16:32:50 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 46 ms on localhost (1/1)
2015-10-29 16:32:50 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.046 s
2015-10-29 16:32:50 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:32:50 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.396261 s
2015-10-29 16:33:56 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50746 in memory (size: 2.2 KB, free: 530.0 MB)
2015-10-29 16:33:56 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:33:56 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50746 in memory (size: 1629.0 B, free: 530.0 MB)
2015-10-29 16:33:56 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:33:56 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:34:00 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:34:00 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:34:01 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:34:01 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:34:01 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:34:01 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:34:01 INFO  Remoting:74 - Starting remoting
2015-10-29 16:34:01 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50750]
2015-10-29 16:34:01 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50750.
2015-10-29 16:34:01 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:34:01 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:34:01 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-6bacaad0-ffae-4e33-af24-a468a9921dd9
2015-10-29 16:34:01 INFO  MemoryStore:59 - MemoryStore started with capacity 524.9 MB
2015-10-29 16:34:01 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-61fcb5f5-12b0-4a1d-846d-b96ca8b53bfd/httpd-977b3032-839e-4569-bbc4-94cbc732f9f4
2015-10-29 16:34:01 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:34:01 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:01 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50751
2015-10-29 16:34:01 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50751.
2015-10-29 16:34:01 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:34:01 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:01 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:01 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@3977a4a5: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:34:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:34:01 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:34:01 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:01 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 16:34:01 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 16:34:01 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 16:34:02 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:34:02 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:34:02 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50752.
2015-10-29 16:34:02 INFO  NettyBlockTransferService:59 - Server created on 50752
2015-10-29 16:34:02 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:34:02 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50752 with 524.9 MB RAM, BlockManagerId(driver, localhost, 50752)
2015-10-29 16:34:02 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:34:03 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:34:03 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:34:03 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=550376570
2015-10-29 16:34:03 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 524.9 MB)
2015-10-29 16:34:03 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=550376570
2015-10-29 16:34:03 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 524.9 MB)
2015-10-29 16:34:03 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50752 (size: 1629.0 B, free: 524.9 MB)
2015-10-29 16:34:03 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:34:03 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:34:03 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2565 bytes)
2015-10-29 16:34:03 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:34:03 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:34:03 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 76 ms on localhost (1/1)
2015-10-29 16:34:03 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:34:03 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.095 s
2015-10-29 16:34:03 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:34:03 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:34:03 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:34:03 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:34:03 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4285, maxMem=550376570
2015-10-29 16:34:03 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 524.9 MB)
2015-10-29 16:34:03 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=8213, maxMem=550376570
2015-10-29 16:34:03 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 524.9 MB)
2015-10-29 16:34:03 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50752 (size: 2.2 KB, free: 524.9 MB)
2015-10-29 16:34:03 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:34:03 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:34:03 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:34:03 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:34:03 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:34:03 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 16:34:03 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1877 bytes result sent to driver
2015-10-29 16:34:03 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 47 ms on localhost (1/1)
2015-10-29 16:34:03 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:34:03 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.048 s
2015-10-29 16:34:03 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.310670 s
2015-10-29 16:34:04 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50752 in memory (size: 2.2 KB, free: 524.9 MB)
2015-10-29 16:34:04 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:34:04 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50752 in memory (size: 1629.0 B, free: 524.9 MB)
2015-10-29 16:34:04 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:34:04 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:34:24 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:34:24 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:34:24 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:34:24 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:34:24 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:34:24 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:34:24 INFO  Remoting:74 - Starting remoting
2015-10-29 16:34:25 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50753]
2015-10-29 16:34:25 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50753.
2015-10-29 16:34:25 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:34:25 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:34:25 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-40fb65c3-0d7d-48de-ad88-8b345e1aa0c7
2015-10-29 16:34:25 INFO  MemoryStore:59 - MemoryStore started with capacity 505.4 MB
2015-10-29 16:34:25 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-07428c46-9a6d-4816-a29b-94962aced407/httpd-bd944895-8425-4938-bf0c-fba422ace852
2015-10-29 16:34:25 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:34:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:25 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50754
2015-10-29 16:34:25 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50754.
2015-10-29 16:34:25 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:34:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@228a51ed: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:34:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:34:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@4748e4dc: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:34:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:34:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:34:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:25 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4042
2015-10-29 16:34:25 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4042.
2015-10-29 16:34:25 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4042
2015-10-29 16:34:25 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:34:25 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:34:25 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50755.
2015-10-29 16:34:25 INFO  NettyBlockTransferService:59 - Server created on 50755
2015-10-29 16:34:25 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:34:25 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50755 with 505.4 MB RAM, BlockManagerId(driver, localhost, 50755)
2015-10-29 16:34:25 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:34:26 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:34:26 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:34:26 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=529992253
2015-10-29 16:34:26 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 505.4 MB)
2015-10-29 16:34:26 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=529992253
2015-10-29 16:34:26 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 505.4 MB)
2015-10-29 16:34:26 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50755 (size: 1629.0 B, free: 505.4 MB)
2015-10-29 16:34:26 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:34:26 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:34:26 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2565 bytes)
2015-10-29 16:34:26 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:34:26 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:34:26 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 92 ms on localhost (1/1)
2015-10-29 16:34:26 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:34:26 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.112 s
2015-10-29 16:34:26 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:34:26 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:34:26 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:34:26 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:34:26 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4285, maxMem=529992253
2015-10-29 16:34:26 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 505.4 MB)
2015-10-29 16:34:26 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=8213, maxMem=529992253
2015-10-29 16:34:26 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 505.4 MB)
2015-10-29 16:34:26 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50755 (size: 2.2 KB, free: 505.4 MB)
2015-10-29 16:34:26 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:34:26 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:34:26 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:34:26 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:34:26 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:34:26 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 16:34:26 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1877 bytes result sent to driver
2015-10-29 16:34:26 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on localhost (1/1)
2015-10-29 16:34:26 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.041 s
2015-10-29 16:34:26 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:34:26 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.322564 s
2015-10-29 16:34:42 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50755 in memory (size: 2.2 KB, free: 505.4 MB)
2015-10-29 16:34:42 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:34:42 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50755 in memory (size: 1629.0 B, free: 505.4 MB)
2015-10-29 16:34:44 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:34:44 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:34:44 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:34:44 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:34:44 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:34:44 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:34:44 INFO  Remoting:74 - Starting remoting
2015-10-29 16:34:44 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50756]
2015-10-29 16:34:44 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50756.
2015-10-29 16:34:44 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:34:44 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:34:44 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-10fc48ec-aebe-49f4-80c1-a2a6a5b32ba4
2015-10-29 16:34:44 INFO  MemoryStore:59 - MemoryStore started with capacity 508.1 MB
2015-10-29 16:34:44 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-b9c9fb89-2d32-4324-9391-d7f572730393/httpd-0c557985-8422-4de8-8030-6ee837d7c0ff
2015-10-29 16:34:44 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:34:44 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:44 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50757
2015-10-29 16:34:44 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50757.
2015-10-29 16:34:44 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:34:45 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:45 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:45 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@53f3f549: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:34:45 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:34:45 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:45 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:45 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@200b12e2: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:34:45 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:34:45 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:45 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:45 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@5ffe2fe3: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:34:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:34:45 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:34:45 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:34:45 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4043
2015-10-29 16:34:45 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4043.
2015-10-29 16:34:45 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4043
2015-10-29 16:34:45 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:34:45 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:34:45 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50758.
2015-10-29 16:34:45 INFO  NettyBlockTransferService:59 - Server created on 50758
2015-10-29 16:34:45 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:34:45 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50758 with 508.1 MB RAM, BlockManagerId(driver, localhost, 50758)
2015-10-29 16:34:45 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:34:46 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:34:46 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125), which has no missing parents
2015-10-29 16:34:46 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=532823408
2015-10-29 16:34:46 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 508.1 MB)
2015-10-29 16:34:46 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=532823408
2015-10-29 16:34:46 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.1 MB)
2015-10-29 16:34:46 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50758 (size: 1631.0 B, free: 508.1 MB)
2015-10-29 16:34:46 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:125)
2015-10-29 16:34:46 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:34:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2565 bytes)
2015-10-29 16:34:46 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:34:46 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:34:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 68 ms on localhost (1/1)
2015-10-29 16:34:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:34:46 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:125) finished in 0.085 s
2015-10-29 16:34:46 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:34:46 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:34:46 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:34:46 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:34:46 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=532823408
2015-10-29 16:34:46 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 508.1 MB)
2015-10-29 16:34:46 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=532823408
2015-10-29 16:34:46 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.1 MB)
2015-10-29 16:34:46 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50758 (size: 2.2 KB, free: 508.1 MB)
2015-10-29 16:34:46 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:34:46 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:34:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:34:46 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:34:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:34:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 8 ms
2015-10-29 16:34:46 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1877 bytes result sent to driver
2015-10-29 16:34:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 52 ms on localhost (1/1)
2015-10-29 16:34:46 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.052 s
2015-10-29 16:34:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:34:46 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.291992 s
2015-10-29 16:37:24 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50758 in memory (size: 2.2 KB, free: 508.1 MB)
2015-10-29 16:37:24 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:37:24 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50758 in memory (size: 1631.0 B, free: 508.1 MB)
2015-10-29 16:37:24 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:37:24 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:37:25 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:37:25 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:37:25 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:37:25 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:37:25 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:37:25 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:37:25 INFO  Remoting:74 - Starting remoting
2015-10-29 16:37:26 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50764]
2015-10-29 16:37:26 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50764.
2015-10-29 16:37:26 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:37:26 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:37:26 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-9ab3e51b-d9e2-49ac-893c-5d92f4eb6113
2015-10-29 16:37:26 INFO  MemoryStore:59 - MemoryStore started with capacity 508.7 MB
2015-10-29 16:37:26 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-e4b8c520-6102-4d58-a53f-67806c6a0b73/httpd-a9c172e4-0575-4349-810b-12ca8b1dfee2
2015-10-29 16:37:26 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:37:26 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:37:26 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50765
2015-10-29 16:37:26 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50765.
2015-10-29 16:37:26 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:37:26 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:37:26 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:37:26 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@6a29044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:37:26 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:37:26 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:37:26 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:37:26 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@49a19c43: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:37:26 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:37:26 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:37:26 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:37:26 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@7fecf294: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:37:26 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:37:26 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:37:26 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:37:26 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@81a7e34: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:37:26 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:37:26 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 16:37:26 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:37:26 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4044
2015-10-29 16:37:26 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4044.
2015-10-29 16:37:26 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4044
2015-10-29 16:37:26 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:37:26 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:37:26 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50766.
2015-10-29 16:37:26 INFO  NettyBlockTransferService:59 - Server created on 50766
2015-10-29 16:37:26 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:37:26 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50766 with 508.7 MB RAM, BlockManagerId(driver, localhost, 50766)
2015-10-29 16:37:26 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:37:27 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:37:27 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83), which has no missing parents
2015-10-29 16:37:27 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=533389639
2015-10-29 16:37:27 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 508.7 MB)
2015-10-29 16:37:27 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=533389639
2015-10-29 16:37:27 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 508.7 MB)
2015-10-29 16:37:27 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50766 (size: 1629.0 B, free: 508.7 MB)
2015-10-29 16:37:27 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:37:27 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:37:27 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 16:37:27 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:37:27 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:37:27 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 76 ms on localhost (1/1)
2015-10-29 16:37:27 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:37:27 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:83) finished in 0.092 s
2015-10-29 16:37:27 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:37:27 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:37:27 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 16:37:27 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4285, maxMem=533389639
2015-10-29 16:37:27 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 508.7 MB)
2015-10-29 16:37:27 INFO  MemoryStore:59 - ensureFreeSpace(2304) called with curMem=8237, maxMem=533389639
2015-10-29 16:37:27 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 508.7 MB)
2015-10-29 16:37:27 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50766 (size: 2.3 KB, free: 508.7 MB)
2015-10-29 16:37:27 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:37:27 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:37:27 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:37:27 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:37:27 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:37:27 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 7 ms
2015-10-29 16:37:27 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:37:27 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 45 ms on localhost (1/1)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.045 s
2015-10-29 16:37:27 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.295273 s
2015-10-29 16:37:27 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:37:27 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:37:27 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:81)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 16:37:27 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10541, maxMem=533389639
2015-10-29 16:37:27 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 508.7 MB)
2015-10-29 16:37:27 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=14469, maxMem=533389639
2015-10-29 16:37:27 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.7 MB)
2015-10-29 16:37:27 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:50766 (size: 2.2 KB, free: 508.7 MB)
2015-10-29 16:37:27 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 16:37:27 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 16:37:27 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:37:27 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 16:37:27 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:37:27 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 16:37:27 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 16:37:27 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 6 ms on localhost (1/1)
2015-10-29 16:37:27 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:81) finished in 0.007 s
2015-10-29 16:37:27 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 16:37:27 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:81, took 0.017325 s
2015-10-29 16:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:37:28 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:50766 in memory (size: 2.2 KB, free: 508.7 MB)
2015-10-29 16:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 16:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50766 in memory (size: 2.3 KB, free: 508.7 MB)
2015-10-29 16:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50766 in memory (size: 1629.0 B, free: 508.7 MB)
2015-10-29 16:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:37:28 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:38:48 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:38:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:38:48 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:38:48 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:38:48 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:38:49 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:38:49 INFO  Remoting:74 - Starting remoting
2015-10-29 16:38:49 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50769]
2015-10-29 16:38:49 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50769.
2015-10-29 16:38:49 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:38:49 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:38:49 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-cbbdebd5-1028-4ae4-afa0-3e2afba6afe1
2015-10-29 16:38:49 INFO  MemoryStore:59 - MemoryStore started with capacity 501.4 MB
2015-10-29 16:38:49 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-274665ec-52b3-4792-bb2b-0b1bb74c0f89/httpd-5b49f0d6-3e49-47c4-a55a-4ed11f131480
2015-10-29 16:38:49 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:38:49 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:38:49 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50770
2015-10-29 16:38:49 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50770.
2015-10-29 16:38:49 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:38:49 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:38:49 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:49 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@318da503: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:38:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:38:49 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:38:49 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:38:49 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:50 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@a47f738: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:38:50 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:38:50 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:38:50 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:50 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@138b9925: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:38:50 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:38:50 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:38:50 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:50 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@6046d2a9: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:38:50 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 16:38:50 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:38:50 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:50 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@69ece4d9: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:38:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:38:50 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2015-10-29 16:38:50 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:38:50 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4045
2015-10-29 16:38:50 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4045.
2015-10-29 16:38:50 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4045
2015-10-29 16:38:50 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:38:50 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:38:50 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50771.
2015-10-29 16:38:50 INFO  NettyBlockTransferService:59 - Server created on 50771
2015-10-29 16:38:50 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:38:50 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50771 with 501.4 MB RAM, BlockManagerId(driver, localhost, 50771)
2015-10-29 16:38:50 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:38:51 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:38:51 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83), which has no missing parents
2015-10-29 16:38:51 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=525745520
2015-10-29 16:38:51 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 501.4 MB)
2015-10-29 16:38:51 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=525745520
2015-10-29 16:38:51 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 501.4 MB)
2015-10-29 16:38:51 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50771 (size: 1629.0 B, free: 501.4 MB)
2015-10-29 16:38:51 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:38:51 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:38:51 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 16:38:51 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:38:51 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:38:51 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 79 ms on localhost (1/1)
2015-10-29 16:38:51 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:38:51 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:83) finished in 0.098 s
2015-10-29 16:38:51 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:38:51 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:38:51 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176), which is now runnable
2015-10-29 16:38:51 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4285, maxMem=525745520
2015-10-29 16:38:51 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 501.4 MB)
2015-10-29 16:38:51 INFO  MemoryStore:59 - ensureFreeSpace(2304) called with curMem=8237, maxMem=525745520
2015-10-29 16:38:51 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 501.4 MB)
2015-10-29 16:38:51 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50771 (size: 2.3 KB, free: 501.4 MB)
2015-10-29 16:38:51 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:38:51 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:38:51 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:38:51 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:38:51 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:38:51 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-29 16:38:51 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:38:51 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 46 ms on localhost (1/1)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.046 s
2015-10-29 16:38:51 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.302212 s
2015-10-29 16:38:51 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:38:51 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:38:51 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:81)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176), which has no missing parents
2015-10-29 16:38:51 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10541, maxMem=525745520
2015-10-29 16:38:51 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 501.4 MB)
2015-10-29 16:38:51 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=14469, maxMem=525745520
2015-10-29 16:38:51 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 501.4 MB)
2015-10-29 16:38:51 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:50771 (size: 2.2 KB, free: 501.4 MB)
2015-10-29 16:38:51 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:38:51 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 16:38:51 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:38:51 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 16:38:51 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:38:51 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 16:38:51 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 16:38:51 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 6 ms on localhost (1/1)
2015-10-29 16:38:51 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:81) finished in 0.006 s
2015-10-29 16:38:51 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 16:38:51 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:81, took 0.015796 s
2015-10-29 16:38:52 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:50771 in memory (size: 2.2 KB, free: 501.4 MB)
2015-10-29 16:38:52 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 16:38:52 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50771 in memory (size: 2.3 KB, free: 501.4 MB)
2015-10-29 16:38:52 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:38:52 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50771 in memory (size: 1629.0 B, free: 501.4 MB)
2015-10-29 16:38:52 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:38:52 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:39:15 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:39:15 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:39:15 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:39:15 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:39:15 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:39:16 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:39:16 INFO  Remoting:74 - Starting remoting
2015-10-29 16:39:16 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50779]
2015-10-29 16:39:16 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50779.
2015-10-29 16:39:16 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:39:16 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:39:16 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-949151b4-9b49-4718-8347-8e76ffee2c9a
2015-10-29 16:39:16 INFO  MemoryStore:59 - MemoryStore started with capacity 507.6 MB
2015-10-29 16:39:16 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-93e04f87-361d-4638-afcb-4529cc751e37/httpd-00f56d24-586c-4420-8d63-3931d11d7d2a
2015-10-29 16:39:16 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:39:16 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:39:16 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50780
2015-10-29 16:39:16 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50780.
2015-10-29 16:39:16 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:39:16 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@2b36d86e: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:39:16 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:39:16 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@5883763d: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:39:16 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:39:16 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@4f057443: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:39:16 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:39:16 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@2abfb70e: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:39:16 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 16:39:16 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@330d2aa3: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:39:16 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:39:17 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2015-10-29 16:39:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:39:17 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4045: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:17 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@38ac8d52: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:39:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:39:17 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
2015-10-29 16:39:17 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:39:17 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4046
2015-10-29 16:39:17 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4046.
2015-10-29 16:39:17 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4046
2015-10-29 16:39:17 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:39:17 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:39:17 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50781.
2015-10-29 16:39:17 INFO  NettyBlockTransferService:59 - Server created on 50781
2015-10-29 16:39:17 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:39:17 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50781 with 507.6 MB RAM, BlockManagerId(driver, localhost, 50781)
2015-10-29 16:39:17 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:40:30 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:40:31 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:40:31 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:40:31 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:40:40 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:40:38 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:40:40 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:40:40 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:40:40 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:40:42 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:40:42 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:40:42 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:40:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:40:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:40:45 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:40:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:40:46 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:40:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:40:43 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:40:47 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:40:47 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:40:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:40:47 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:40:53 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:40:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:40:53 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:40:51 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:40:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:40:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:40:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:40:56 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:40:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:40:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:40:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:40:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:41:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:41:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:41:02 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:41:02 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:41:01 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:41:02 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:41:02 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:41:02 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:41:05 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:41:04 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:41:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:41:07 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:41:07 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:41:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:41:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:41:09 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:41:08 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:41:13 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:41:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:41:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:41:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:41:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:41:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:41:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 16:41:16 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4043
2015-10-29 16:41:17 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4042
2015-10-29 16:41:17 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:41:19 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:41:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:41:19 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:41:19 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:41:19 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:41:21 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:41:21 INFO  Remoting:74 - Starting remoting
2015-10-29 16:41:21 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50785]
2015-10-29 16:41:21 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50785.
2015-10-29 16:41:21 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:41:21 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:41:21 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-fcd1c70f-c991-4ea9-8f9d-7bcaaa9c1a9f
2015-10-29 16:41:21 INFO  MemoryStore:59 - MemoryStore started with capacity 530.0 MB
2015-10-29 16:41:21 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-6b9ad5f5-889c-48c4-afdd-47b3a4a5d30a/httpd-3b2b8306-0ccd-4e24-ac2a-fef015f3b7eb
2015-10-29 16:41:21 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:41:21 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:41:21 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50786
2015-10-29 16:41:21 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50786.
2015-10-29 16:41:22 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:41:22 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:41:22 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:41:22 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 16:41:22 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 16:41:22 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 16:41:22 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:41:22 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:41:23 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50787.
2015-10-29 16:41:23 INFO  NettyBlockTransferService:59 - Server created on 50787
2015-10-29 16:41:23 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:41:23 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50787 with 530.0 MB RAM, BlockManagerId(driver, localhost, 50787)
2015-10-29 16:41:23 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:41:21 WARN  ShutdownHookManager:56 - ShutdownHook '$anon$2' failed, java.lang.OutOfMemoryError: Metaspace
java.lang.OutOfMemoryError: Metaspace
2015-10-29 16:41:25 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:41:25 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83), which has no missing parents
2015-10-29 16:41:25 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=555755765
2015-10-29 16:41:25 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 16:41:25 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=555755765
2015-10-29 16:41:25 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 530.0 MB)
2015-10-29 16:41:25 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50787 (size: 1629.0 B, free: 530.0 MB)
2015-10-29 16:41:25 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:41:25 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:41:25 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 16:41:25 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:41:25 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:41:25 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 137 ms on localhost (1/1)
2015-10-29 16:41:25 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:41:25 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:83) finished in 0.188 s
2015-10-29 16:41:25 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:41:25 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:41:25 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:41:25 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176), which is now runnable
2015-10-29 16:41:25 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4285, maxMem=555755765
2015-10-29 16:41:25 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 530.0 MB)
2015-10-29 16:41:25 INFO  MemoryStore:59 - ensureFreeSpace(2304) called with curMem=8237, maxMem=555755765
2015-10-29 16:41:25 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 530.0 MB)
2015-10-29 16:41:25 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50787 (size: 2.3 KB, free: 530.0 MB)
2015-10-29 16:41:25 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:41:25 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:41:25 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:41:25 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:41:25 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:41:25 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 7 ms
2015-10-29 16:41:25 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:41:25 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 64 ms on localhost (1/1)
2015-10-29 16:41:25 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:41:25 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.065 s
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.730663 s
2015-10-29 16:41:25 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:41:25 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:41:25 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:81)
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176), which has no missing parents
2015-10-29 16:41:25 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10541, maxMem=555755765
2015-10-29 16:41:25 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 530.0 MB)
2015-10-29 16:41:25 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=14469, maxMem=555755765
2015-10-29 16:41:25 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 530.0 MB)
2015-10-29 16:41:25 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:50787 (size: 2.2 KB, free: 530.0 MB)
2015-10-29 16:41:25 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:41:25 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 16:41:25 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:41:25 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 16:41:25 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:41:25 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 16:41:25 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 16:41:25 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 14 ms on localhost (1/1)
2015-10-29 16:41:25 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 16:41:25 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:81) finished in 0.015 s
2015-10-29 16:41:25 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:81, took 0.036867 s
2015-10-29 16:41:28 WARN  ShutdownHookManager:56 - ShutdownHook '$anon$2' failed, java.lang.OutOfMemoryError: Metaspace
java.lang.OutOfMemoryError: Metaspace
2015-10-29 16:41:31 WARN  ShutdownHookManager:56 - ShutdownHook '$anon$2' failed, java.lang.OutOfMemoryError: Metaspace
java.lang.OutOfMemoryError: Metaspace
2015-10-29 16:41:34 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:41:44 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:50787 in memory (size: 2.2 KB, free: 530.0 MB)
2015-10-29 16:41:44 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 16:41:44 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50787 in memory (size: 2.3 KB, free: 530.0 MB)
2015-10-29 16:41:44 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:41:44 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50787 in memory (size: 1629.0 B, free: 530.0 MB)
2015-10-29 16:41:44 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:41:44 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:41:47 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:41:48 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:41:48 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:41:48 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:41:48 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:41:48 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:41:48 INFO  Remoting:74 - Starting remoting
2015-10-29 16:41:49 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50790]
2015-10-29 16:41:49 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50790.
2015-10-29 16:41:49 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:41:49 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:41:49 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-232890ae-acb7-4ee6-bb10-d679e2d4067a
2015-10-29 16:41:49 INFO  MemoryStore:59 - MemoryStore started with capacity 497.9 MB
2015-10-29 16:41:49 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-5f008a85-57a8-4a94-8687-533721220ee0/httpd-2ebff731-0499-4aac-a794-3e2905c7df3c
2015-10-29 16:41:49 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:41:49 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:41:49 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50791
2015-10-29 16:41:49 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50791.
2015-10-29 16:41:49 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:41:49 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:41:49 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:41:49 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@1d6aca45: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:41:49 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:41:49 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:41:49 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:41:49 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 16:41:49 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 16:41:49 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 16:41:49 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:41:49 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:41:50 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50792.
2015-10-29 16:41:50 INFO  NettyBlockTransferService:59 - Server created on 50792
2015-10-29 16:41:50 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:41:50 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50792 with 497.9 MB RAM, BlockManagerId(driver, localhost, 50792)
2015-10-29 16:41:50 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:41:51 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:41:51 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83), which has no missing parents
2015-10-29 16:41:51 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=522065018
2015-10-29 16:41:51 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 497.9 MB)
2015-10-29 16:41:51 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=522065018
2015-10-29 16:41:51 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 497.9 MB)
2015-10-29 16:41:51 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50792 (size: 1629.0 B, free: 497.9 MB)
2015-10-29 16:41:51 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:41:51 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:41:51 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 16:41:51 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:41:51 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:41:51 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 118 ms on localhost (1/1)
2015-10-29 16:41:51 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:41:51 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:83) finished in 0.185 s
2015-10-29 16:41:51 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:41:51 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:41:51 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:41:51 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176), which is now runnable
2015-10-29 16:41:51 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4285, maxMem=522065018
2015-10-29 16:41:51 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 497.9 MB)
2015-10-29 16:41:51 INFO  MemoryStore:59 - ensureFreeSpace(2304) called with curMem=8237, maxMem=522065018
2015-10-29 16:41:51 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 497.9 MB)
2015-10-29 16:41:51 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50792 (size: 2.3 KB, free: 497.9 MB)
2015-10-29 16:41:51 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:41:51 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:41:51 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:41:51 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:41:51 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:41:51 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:41:51 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 7 ms
2015-10-29 16:41:52 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:41:52 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 78 ms on localhost (1/1)
2015-10-29 16:41:52 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.078 s
2015-10-29 16:41:52 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:41:52 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.600425 s
2015-10-29 16:41:52 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:41:52 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:41:52 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 16:41:52 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:41:52 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:81)
2015-10-29 16:41:52 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 16:41:52 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 16:41:52 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176), which has no missing parents
2015-10-29 16:41:52 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10541, maxMem=522065018
2015-10-29 16:41:52 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 497.9 MB)
2015-10-29 16:41:52 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=14469, maxMem=522065018
2015-10-29 16:41:52 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 497.9 MB)
2015-10-29 16:41:52 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:50792 (size: 2.2 KB, free: 497.9 MB)
2015-10-29 16:41:52 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 16:41:52 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:41:52 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 16:41:52 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:41:52 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 16:41:52 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:41:52 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 16:41:52 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 16:41:52 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 12 ms on localhost (1/1)
2015-10-29 16:41:52 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 16:41:52 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:81) finished in 0.013 s
2015-10-29 16:41:52 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:81, took 0.030781 s
2015-10-29 16:41:52 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:41:53 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:50792 in memory (size: 2.2 KB, free: 497.9 MB)
2015-10-29 16:41:53 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 16:41:53 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50792 in memory (size: 2.3 KB, free: 497.9 MB)
2015-10-29 16:41:53 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:41:53 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50792 in memory (size: 1629.0 B, free: 497.9 MB)
2015-10-29 16:41:53 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:41:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:04 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:42:04 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:42:05 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:42:05 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:42:05 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:42:05 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:42:05 INFO  Remoting:74 - Starting remoting
2015-10-29 16:42:05 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50793]
2015-10-29 16:42:05 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50793.
2015-10-29 16:42:05 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:42:06 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:42:06 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-a3d548d3-46ee-4385-acdb-b23e7647ee19
2015-10-29 16:42:06 INFO  MemoryStore:59 - MemoryStore started with capacity 503.3 MB
2015-10-29 16:42:06 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-58343569-e455-4d51-8cca-ef99fc88a85d/httpd-20c694f5-088a-4cb4-ab4d-eabcdf6aa719
2015-10-29 16:42:06 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:42:06 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:06 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50794
2015-10-29 16:42:06 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50794.
2015-10-29 16:42:06 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:42:06 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:06 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:06 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@1930dcea: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:06 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:42:06 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:06 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:06 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@60fdde89: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:06 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:06 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:42:06 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:06 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4042
2015-10-29 16:42:06 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4042.
2015-10-29 16:42:06 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4042
2015-10-29 16:42:06 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:42:06 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:42:06 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50795.
2015-10-29 16:42:06 INFO  NettyBlockTransferService:59 - Server created on 50795
2015-10-29 16:42:06 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:42:06 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50795 with 503.3 MB RAM, BlockManagerId(driver, localhost, 50795)
2015-10-29 16:42:06 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:42:07 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:42:07 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:42:07 INFO  DAGScheduler:59 - Registering RDD 0 (parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:42:07 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:42:07 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:42:07 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:42:07 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:42:07 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83), which has no missing parents
2015-10-29 16:42:08 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=527727329
2015-10-29 16:42:08 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 503.3 MB)
2015-10-29 16:42:08 INFO  MemoryStore:59 - ensureFreeSpace(1629) called with curMem=2656, maxMem=527727329
2015-10-29 16:42:08 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1629.0 B, free 503.3 MB)
2015-10-29 16:42:08 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50795 (size: 1629.0 B, free: 503.3 MB)
2015-10-29 16:42:08 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[0] at parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:42:08 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:42:08 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 16:42:08 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:42:08 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:42:08 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 87 ms on localhost (1/1)
2015-10-29 16:42:08 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:83) finished in 0.105 s
2015-10-29 16:42:08 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:42:08 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:42:08 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:42:08 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:42:08 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176), which is now runnable
2015-10-29 16:42:08 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4285, maxMem=527727329
2015-10-29 16:42:08 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 503.3 MB)
2015-10-29 16:42:08 INFO  MemoryStore:59 - ensureFreeSpace(2304) called with curMem=8237, maxMem=527727329
2015-10-29 16:42:08 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 503.3 MB)
2015-10-29 16:42:08 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50795 (size: 2.3 KB, free: 503.3 MB)
2015-10-29 16:42:08 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:42:08 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:42:08 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:42:08 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:42:08 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:42:08 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 7 ms
2015-10-29 16:42:08 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:42:08 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 54 ms on localhost (1/1)
2015-10-29 16:42:08 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:42:08 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.055 s
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.455035 s
2015-10-29 16:42:08 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:42:08 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:42:08 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:81)
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176), which has no missing parents
2015-10-29 16:42:08 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10541, maxMem=527727329
2015-10-29 16:42:08 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 503.3 MB)
2015-10-29 16:42:08 INFO  MemoryStore:59 - ensureFreeSpace(2284) called with curMem=14469, maxMem=527727329
2015-10-29 16:42:08 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 503.3 MB)
2015-10-29 16:42:08 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:50795 (size: 2.2 KB, free: 503.3 MB)
2015-10-29 16:42:08 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[2] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:42:08 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 16:42:08 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:42:08 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 16:42:08 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:42:08 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 16:42:08 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 16:42:08 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 11 ms on localhost (1/1)
2015-10-29 16:42:08 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 16:42:08 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:81) finished in 0.011 s
2015-10-29 16:42:08 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:81, took 0.026016 s
2015-10-29 16:42:09 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:18 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:20 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:50795 in memory (size: 2.2 KB, free: 503.3 MB)
2015-10-29 16:42:20 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 16:42:20 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:50795 in memory (size: 2.3 KB, free: 503.3 MB)
2015-10-29 16:42:20 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 16:42:20 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:50795 in memory (size: 1629.0 B, free: 503.3 MB)
2015-10-29 16:42:20 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 16:42:20 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 16:42:23 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 16:42:24 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 16:42:24 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 16:42:24 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 16:42:24 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 16:42:24 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 16:42:24 INFO  Remoting:74 - Starting remoting
2015-10-29 16:42:25 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:50796]
2015-10-29 16:42:25 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 50796.
2015-10-29 16:42:25 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 16:42:25 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 16:42:25 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-a746e9df-7636-4930-9a9d-b9a6ff418ef4
2015-10-29 16:42:25 INFO  MemoryStore:59 - MemoryStore started with capacity 503.5 MB
2015-10-29 16:42:25 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-595f1aac-f381-4275-8f1a-f28616e5d38e/httpd-a81e6fd0-6e3f-4d28-a217-930a1fc514b7
2015-10-29 16:42:25 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 16:42:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:25 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:50797
2015-10-29 16:42:25 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 50797.
2015-10-29 16:42:25 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 16:42:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@55bcef74: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 16:42:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@40d24311: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 16:42:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@1780d6bf: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 16:42:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 16:42:25 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4043
2015-10-29 16:42:25 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4043.
2015-10-29 16:42:25 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4043
2015-10-29 16:42:26 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 16:42:26 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 16:42:26 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50798.
2015-10-29 16:42:26 INFO  NettyBlockTransferService:59 - Server created on 50798
2015-10-29 16:42:26 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 16:42:26 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:50798 with 503.5 MB RAM, BlockManagerId(driver, localhost, 50798)
2015-10-29 16:42:26 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 16:42:27 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:42:27 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:81)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:83), which has no missing parents
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 503.5 MB)
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 503.5 MB)
2015-10-29 16:42:27 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:50798 (size: 1631.0 B, free: 503.5 MB)
2015-10-29 16:42:27 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:83)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 16:42:27 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 16:42:27 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 104 ms on localhost (1/1)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 16:42:27 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:83) finished in 0.143 s
2015-10-29 16:42:27 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:42:27 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:42:27 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:176), which is now runnable
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 503.5 MB)
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 503.5 MB)
2015-10-29 16:42:27 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:50798 (size: 2.3 KB, free: 503.5 MB)
2015-10-29 16:42:27 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:42:27 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 16:42:27 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:42:27 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 16:42:27 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 49 ms on localhost (1/1)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:81) finished in 0.050 s
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:81, took 0.396415 s
2015-10-29 16:42:27 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:42:27 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:42:27 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:81)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:176), which has no missing parents
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10559, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 503.5 MB)
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14487, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 503.5 MB)
2015-10-29 16:42:27 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:50798 (size: 2.2 KB, free: 503.5 MB)
2015-10-29 16:42:27 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:42:27 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 16:42:27 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:42:27 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 16:42:27 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 19 ms on localhost (1/1)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 16:42:27 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:81) finished in 0.020 s
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:81, took 0.037609 s
2015-10-29 16:42:27 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 16:42:27 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:81
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:112)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:81) with 1 output partitions
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Final stage: ResultStage 5(runJob at IntervalRDD.scala:81)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 4)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 4)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:112), which has no missing parents
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16789, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 503.5 MB)
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19445, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 503.5 MB)
2015-10-29 16:42:27 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:50798 (size: 1631.0 B, free: 503.5 MB)
2015-10-29 16:42:27 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:112)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2565 bytes)
2015-10-29 16:42:27 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 16:42:27 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 12 ms on localhost (1/1)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 16:42:27 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:112) finished in 0.014 s
2015-10-29 16:42:27 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 16:42:27 INFO  DAGScheduler:59 - running: Set()
2015-10-29 16:42:27 INFO  DAGScheduler:59 - waiting: Set(ResultStage 5)
2015-10-29 16:42:27 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Missing parents for ResultStage 5: List()
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting ResultStage 5 (MapPartitionsRDD[10] at mapPartitions at IntervalRDD.scala:176), which is now runnable
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=21076, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 3.8 KB, free 503.5 MB)
2015-10-29 16:42:27 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=25004, maxMem=528010444
2015-10-29 16:42:27 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.2 KB, free 503.5 MB)
2015-10-29 16:42:27 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:50798 (size: 2.2 KB, free: 503.5 MB)
2015-10-29 16:42:27 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[10] at mapPartitions at IntervalRDD.scala:176)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 16:42:27 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 16:42:27 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 16:42:27 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 16:42:27 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1877 bytes result sent to driver
2015-10-29 16:42:27 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 11 ms on localhost (1/1)
2015-10-29 16:42:27 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 16:42:27 INFO  DAGScheduler:59 - ResultStage 5 (runJob at IntervalRDD.scala:81) finished in 0.012 s
2015-10-29 16:42:27 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:81, took 0.049777 s
2015-10-29 16:42:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:33 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:42:33 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:42:33 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:42:33 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 16:42:33 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 16:42:33 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4042
2015-10-29 16:42:33 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 16:42:33 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:42:33 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 16:42:33 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:42:33 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4043
2015-10-29 16:42:33 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:42:33 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 16:42:33 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 16:42:33 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 16:42:33 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 16:42:33 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 16:42:33 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 16:42:33 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 16:42:33 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 16:42:33 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 16:42:33 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 16:42:33 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 16:42:33 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 16:42:33 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 16:42:33 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-6b9ad5f5-889c-48c4-afdd-47b3a4a5d30a
2015-10-29 16:42:33 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 16:42:33 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 16:42:33 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 16:42:33 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 16:42:33 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 16:42:33 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 16:42:33 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 16:42:33 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 16:42:33 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 16:42:33 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 16:42:33 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 16:42:33 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 16:42:33 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 16:42:33 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-5f008a85-57a8-4a94-8687-533721220ee0
2015-10-29 16:42:33 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 16:42:33 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 16:42:33 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 16:42:33 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 16:42:33 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 16:42:33 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 16:42:33 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 16:42:33 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-58343569-e455-4d51-8cca-ef99fc88a85d
2015-10-29 16:42:33 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 16:42:33 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 16:42:33 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-595f1aac-f381-4275-8f1a-f28616e5d38e
