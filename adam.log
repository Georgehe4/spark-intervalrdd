2015-10-27 16:25:24 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-27 16:25:25 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-27 16:25:25 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-27 16:25:25 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-27 16:25:25 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-27 16:25:26 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-27 16:25:27 INFO  Remoting:74 - Starting remoting
2015-10-27 16:25:27 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:54473]
2015-10-27 16:25:27 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 54473.
2015-10-27 16:25:27 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-27 16:25:27 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-27 16:25:27 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-10b29551-2c68-4a9b-98c0-b96f28ad9e51
2015-10-27 16:25:27 INFO  MemoryStore:59 - MemoryStore started with capacity 491.7 MB
2015-10-27 16:25:27 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-066c5814-7d0e-4058-bbb3-9be51f84c1b2/httpd-8e67f3a2-5fd8-4cb0-9180-9df88c412951
2015-10-27 16:25:27 INFO  HttpServer:59 - Starting HTTP Server
2015-10-27 16:25:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-27 16:25:27 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:54474
2015-10-27 16:25:27 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 54474.
2015-10-27 16:25:27 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-27 16:25:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-27 16:25:27 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-27 16:25:27 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-27 16:25:27 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-27 16:25:27 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-27 16:25:27 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-27 16:25:27 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54475.
2015-10-27 16:25:27 INFO  NettyBlockTransferService:59 - Server created on 54475
2015-10-27 16:25:27 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-27 16:25:27 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:54475 with 491.7 MB RAM, BlockManagerId(driver, localhost, 54475)
2015-10-27 16:25:27 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-27 16:25:28 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-27 16:25:28 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-27 16:25:28 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=515553361
2015-10-27 16:25:28 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 491.7 MB)
2015-10-27 16:25:28 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=515553361
2015-10-27 16:25:28 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 491.7 MB)
2015-10-27 16:25:28 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:54475 (size: 1631.0 B, free: 491.7 MB)
2015-10-27 16:25:28 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-27 16:25:28 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-27 16:25:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-27 16:25:28 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-27 16:25:28 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 112 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.147 s
2015-10-27 16:25:29 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-27 16:25:29 INFO  DAGScheduler:59 - running: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - failed: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:178), which is now runnable
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:54475 (size: 2.2 KB, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:178)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 86 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.087 s
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.527933 s
2015-10-27 16:25:29 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-27 16:25:29 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-27 16:25:29 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:178), which has no missing parents
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:54475 (size: 2.2 KB, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:178)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 7 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.007 s
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.020523 s
2015-10-27 16:25:29 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-27 16:25:29 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 491.7 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 491.6 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:54475 (size: 1631.0 B, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 491.6 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 491.6 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:54475 (size: 1633.0 B, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.016 s
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 15 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - failed: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 16 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.023 s
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-27 16:25:29 INFO  DAGScheduler:59 - running: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - failed: Set()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 491.6 MB)
2015-10-27 16:25:29 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=515553361
2015-10-27 16:25:29 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 491.6 MB)
2015-10-27 16:25:29 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:54475 (size: 2.9 KB, free: 491.7 MB)
2015-10-27 16:25:29 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-27 16:25:29 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-27 16:25:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-27 16:25:29 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-27 16:25:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 19 ms on localhost (1/1)
2015-10-27 16:25:29 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.019 s
2015-10-27 16:25:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-27 16:25:29 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.076743 s
2015-10-27 17:00:50 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-27 17:00:50 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-27 17:00:51 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-27 17:00:51 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-27 17:00:51 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-27 17:00:51 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-27 17:00:51 INFO  BlockManager:59 - BlockManager stopped
2015-10-27 17:00:51 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-27 17:00:51 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-27 17:00:51 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-27 17:00:51 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-27 17:00:51 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-066c5814-7d0e-4058-bbb3-9be51f84c1b2
2015-10-28 14:02:43 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-28 14:02:44 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-28 14:02:44 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-28 14:02:44 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-28 14:02:44 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-28 14:02:44 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-28 14:02:44 INFO  Remoting:74 - Starting remoting
2015-10-28 14:02:45 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.105.138.61:58691]
2015-10-28 14:02:45 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 58691.
2015-10-28 14:02:45 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-28 14:02:45 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-28 14:02:45 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-0033a052-3c9e-4a08-96f5-4c07e0f0fa8d
2015-10-28 14:02:45 INFO  MemoryStore:59 - MemoryStore started with capacity 508.1 MB
2015-10-28 14:02:45 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-694b33c0-8107-4063-a224-1c0a5e554b55/httpd-a4e95429-9ed4-4ab6-93f0-6efc4b1ee23a
2015-10-28 14:02:45 INFO  HttpServer:59 - Starting HTTP Server
2015-10-28 14:02:45 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-28 14:02:45 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:58692
2015-10-28 14:02:45 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 58692.
2015-10-28 14:02:45 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-28 14:02:45 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-28 14:02:45 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-28 14:02:45 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-28 14:02:45 INFO  SparkUI:59 - Started SparkUI at http://10.105.138.61:4040
2015-10-28 14:02:45 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-28 14:02:45 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-28 14:02:45 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58693.
2015-10-28 14:02:45 INFO  NettyBlockTransferService:59 - Server created on 58693
2015-10-28 14:02:45 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-28 14:02:45 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:58693 with 508.1 MB RAM, BlockManagerId(driver, localhost, 58693)
2015-10-28 14:02:45 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-28 14:02:46 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-28 14:02:46 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:58693 (size: 1631.0 B, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 100 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.120 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-28 14:02:46 INFO  DAGScheduler:59 - running: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - failed: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:58693 (size: 2.2 KB, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 51 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.052 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.457130 s
2015-10-28 14:02:46 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-28 14:02:46 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-28 14:02:46 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:58693 (size: 2.2 KB, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 12 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.012 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.026363 s
2015-10-28 14:02:46 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-28 14:02:46 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:58693 (size: 1631.0 B, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:58693 (size: 1633.0 B, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 19 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.019 s
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-28 14:02:46 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - failed: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 12 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.021 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-28 14:02:46 INFO  DAGScheduler:59 - running: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-28 14:02:46 INFO  DAGScheduler:59 - failed: Set()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=532823408
2015-10-28 14:02:46 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 508.1 MB)
2015-10-28 14:02:46 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:58693 (size: 2.9 KB, free: 508.1 MB)
2015-10-28 14:02:46 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-28 14:02:46 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-28 14:02:46 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-28 14:02:46 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-28 14:02:46 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 19 ms on localhost (1/1)
2015-10-28 14:02:46 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-28 14:02:46 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.019 s
2015-10-28 14:02:46 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.077835 s
2015-10-28 14:27:48 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-28 14:27:48 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-28 14:27:49 INFO  SparkUI:59 - Stopped Spark web UI at http://10.105.138.61:4040
2015-10-28 14:27:49 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-28 14:27:49 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-28 14:27:49 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-28 14:27:49 INFO  BlockManager:59 - BlockManager stopped
2015-10-28 14:27:49 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-28 14:27:49 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-28 14:27:49 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-28 14:27:49 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-28 14:27:49 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-694b33c0-8107-4063-a224-1c0a5e554b55
2015-10-29 11:37:34 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 11:37:34 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 11:37:34 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 11:37:34 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 11:37:34 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 11:37:35 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 11:37:35 INFO  Remoting:74 - Starting remoting
2015-10-29 11:37:35 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:64790]
2015-10-29 11:37:35 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 64790.
2015-10-29 11:37:35 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 11:37:35 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 11:37:35 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-4902fe2f-18a3-4157-b3b4-d5e4bfe18011
2015-10-29 11:37:35 INFO  MemoryStore:59 - MemoryStore started with capacity 507.6 MB
2015-10-29 11:37:35 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-858ab31d-7aaf-440c-9cec-38e9b56988f0/httpd-6792d7ff-967d-4d59-be98-b9546abd08e9
2015-10-29 11:37:35 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 11:37:35 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 11:37:35 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:64791
2015-10-29 11:37:35 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 64791.
2015-10-29 11:37:35 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 11:37:35 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 11:37:35 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 11:37:35 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 11:37:35 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 11:37:35 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 11:37:35 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 11:37:36 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64792.
2015-10-29 11:37:36 INFO  NettyBlockTransferService:59 - Server created on 64792
2015-10-29 11:37:36 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 11:37:36 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:64792 with 507.6 MB RAM, BlockManagerId(driver, localhost, 64792)
2015-10-29 11:37:36 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 11:37:36 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 11:37:36 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 11:37:36 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=532257177
2015-10-29 11:37:36 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 507.6 MB)
2015-10-29 11:37:36 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=532257177
2015-10-29 11:37:36 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 507.6 MB)
2015-10-29 11:37:36 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:64792 (size: 1631.0 B, free: 507.6 MB)
2015-10-29 11:37:36 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 11:37:36 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 11:37:36 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 11:37:36 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 11:37:36 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 11:37:36 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 84 ms on localhost (1/1)
2015-10-29 11:37:36 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 11:37:36 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.099 s
2015-10-29 11:37:36 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 11:37:36 INFO  DAGScheduler:59 - running: Set()
2015-10-29 11:37:36 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 11:37:36 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 11:37:36 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=532257177
2015-10-29 11:37:36 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 507.6 MB)
2015-10-29 11:37:36 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=532257177
2015-10-29 11:37:36 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 507.6 MB)
2015-10-29 11:37:36 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:64792 (size: 2.2 KB, free: 507.6 MB)
2015-10-29 11:37:36 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:36 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 11:37:36 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 11:37:36 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 11:37:36 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.043 s
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.380091 s
2015-10-29 11:37:37 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 11:37:37 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 11:37:37 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:64792 (size: 2.2 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 11:37:37 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 6 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.007 s
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.017999 s
2015-10-29 11:37:37 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 11:37:37 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 507.6 MB)
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:64792 (size: 1631.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 11:37:37 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 507.6 MB)
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:64792 (size: 1633.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 11:37:37 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 14 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.015 s
2015-10-29 11:37:37 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 11:37:37 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 16 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.021 s
2015-10-29 11:37:37 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 11:37:37 INFO  DAGScheduler:59 - running: Set()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=532257177
2015-10-29 11:37:37 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 507.6 MB)
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:64792 (size: 2.9 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 11:37:37 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 11:37:37 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 11:37:37 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-29 11:37:37 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 19 ms on localhost (1/1)
2015-10-29 11:37:37 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.019 s
2015-10-29 11:37:37 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-29 11:37:37 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.076125 s
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_5_piece0 on localhost:64792 in memory (size: 2.9 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 6
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:64792 in memory (size: 1633.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:64792 in memory (size: 1631.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:64792 in memory (size: 2.2 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:64792 in memory (size: 2.2 KB, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 11:37:37 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:64792 in memory (size: 1631.0 B, free: 507.6 MB)
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 11:37:37 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:28:30 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:28:30 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:28:30 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:28:30 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:28:30 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:28:30 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:28:31 INFO  Remoting:74 - Starting remoting
2015-10-29 13:28:31 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:65516]
2015-10-29 13:28:31 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 65516.
2015-10-29 13:28:31 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:28:31 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:28:31 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-d338b392-227a-47cc-96ff-4f948f17aa19
2015-10-29 13:28:31 INFO  MemoryStore:59 - MemoryStore started with capacity 507.1 MB
2015-10-29 13:28:31 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-c76c87fd-9209-45de-8656-d48d028b0a6b/httpd-b33cb172-f05c-4977-8085-9dfbdf86f88e
2015-10-29 13:28:31 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:28:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:28:31 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:65517
2015-10-29 13:28:31 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 65517.
2015-10-29 13:28:31 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:28:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:28:31 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:28:31 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@43c047b2: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:28:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:28:31 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:28:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:28:31 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 13:28:31 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 13:28:31 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 13:28:31 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:28:31 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:28:31 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65518.
2015-10-29 13:28:31 INFO  NettyBlockTransferService:59 - Server created on 65518
2015-10-29 13:28:31 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:28:31 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:65518 with 507.1 MB RAM, BlockManagerId(driver, localhost, 65518)
2015-10-29 13:28:31 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:28:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:28:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 507.1 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 507.1 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:65518 (size: 1631.0 B, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 69 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.083 s
2015-10-29 13:28:32 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:28:32 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 507.1 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:65518 (size: 2.2 KB, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 47 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.047 s
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.281368 s
2015-10-29 13:28:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:28:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:28:32 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:65518 (size: 2.2 KB, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 7 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.008 s
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.020885 s
2015-10-29 13:28:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:28:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:65518 (size: 1631.0 B, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:65518 (size: 1633.0 B, free: 507.1 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 17 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.018 s
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:28:32 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 9 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.016 s
2015-10-29 13:28:32 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:28:32 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=531690946
2015-10-29 13:28:32 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 507.0 MB)
2015-10-29 13:28:32 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:65518 (size: 2.9 KB, free: 507.0 MB)
2015-10-29 13:28:32 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 13:28:32 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:28:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:28:32 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-29 13:28:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 19 ms on localhost (1/1)
2015-10-29 13:28:32 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.020 s
2015-10-29 13:28:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-29 13:28:32 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.064359 s
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_5_piece0 on localhost:65518 in memory (size: 2.9 KB, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 6
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:65518 in memory (size: 1633.0 B, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:65518 in memory (size: 1631.0 B, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:65518 in memory (size: 2.2 KB, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:65518 in memory (size: 2.2 KB, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:28:33 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:65518 in memory (size: 1631.0 B, free: 507.1 MB)
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:28:33 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:29:55 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 13:29:55 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:29:55 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:29:55 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 13:29:55 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 13:29:55 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 13:29:55 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 13:29:55 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 13:29:55 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 13:29:55 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 13:29:55 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 13:29:55 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 13:29:55 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 13:29:55 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 13:29:55 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 13:29:55 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 13:29:55 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 13:29:55 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 13:29:55 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 13:29:55 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 13:29:55 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-c76c87fd-9209-45de-8656-d48d028b0a6b
2015-10-29 13:29:55 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 13:29:55 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-858ab31d-7aaf-440c-9cec-38e9b56988f0
2015-10-29 13:31:41 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:31:41 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:31:41 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:31:41 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:31:41 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:31:42 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:31:42 INFO  Remoting:74 - Starting remoting
2015-10-29 13:31:43 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:65534]
2015-10-29 13:31:43 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 65534.
2015-10-29 13:31:43 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:31:43 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:31:43 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-ba79c69b-c2f7-4b33-a992-a2220d9cfaed
2015-10-29 13:31:43 INFO  MemoryStore:59 - MemoryStore started with capacity 530.0 MB
2015-10-29 13:31:43 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-47efdc31-ca72-42ae-94cd-993bd0b24d49/httpd-e358d1f7-5726-4126-8c0c-d4ac6361a2c9
2015-10-29 13:31:43 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:31:43 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:31:43 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:65535
2015-10-29 13:31:43 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 65535.
2015-10-29 13:31:43 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:31:43 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:31:43 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 13:31:43 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 13:31:43 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 13:31:43 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:31:43 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:31:43 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49152.
2015-10-29 13:31:43 INFO  NettyBlockTransferService:59 - Server created on 49152
2015-10-29 13:31:43 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:31:43 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49152 with 530.0 MB RAM, BlockManagerId(driver, localhost, 49152)
2015-10-29 13:31:43 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:31:44 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:31:44 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49152 (size: 1631.0 B, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 81 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.102 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:31:44 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49152 (size: 2.2 KB, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 48 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.049 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.371321 s
2015-10-29 13:31:44 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:31:44 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:31:44 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49152 (size: 2.2 KB, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 8 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.010 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.023929 s
2015-10-29 13:31:44 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:31:44 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:49152 (size: 1631.0 B, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:49152 (size: 1633.0 B, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 14 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.015 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:31:44 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 17 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.021 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:31:44 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:31:44 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=555755765
2015-10-29 13:31:44 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 530.0 MB)
2015-10-29 13:31:44 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:49152 (size: 2.9 KB, free: 530.0 MB)
2015-10-29 13:31:44 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 13:31:44 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:31:44 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:31:44 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-29 13:31:44 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 21 ms on localhost (1/1)
2015-10-29 13:31:44 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-29 13:31:44 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.021 s
2015-10-29 13:31:44 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.082858 s
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_5_piece0 on localhost:49152 in memory (size: 2.9 KB, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 6
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:49152 in memory (size: 1633.0 B, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:49152 in memory (size: 1631.0 B, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49152 in memory (size: 2.2 KB, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49152 in memory (size: 2.2 KB, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:31:45 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49152 in memory (size: 1631.0 B, free: 530.0 MB)
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:31:45 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:36:19 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:36:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:36:19 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:36:19 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:36:19 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:36:19 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:36:19 INFO  Remoting:74 - Starting remoting
2015-10-29 13:36:20 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49154]
2015-10-29 13:36:20 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49154.
2015-10-29 13:36:20 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:36:20 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:36:20 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-ba3f6c3d-e3b7-4e48-9cec-512304303369
2015-10-29 13:36:20 INFO  MemoryStore:59 - MemoryStore started with capacity 503.3 MB
2015-10-29 13:36:20 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-091374ae-5d69-49dc-88ba-bb513234b47a/httpd-382b1eed-aace-4b43-86d9-5ce383d9757f
2015-10-29 13:36:20 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:36:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:36:20 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49155
2015-10-29 13:36:20 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49155.
2015-10-29 13:36:20 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:36:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:36:20 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:36:20 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@74cb163: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:36:20 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:36:20 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:36:20 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:36:20 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 13:36:20 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 13:36:20 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 13:36:20 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:36:20 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:36:20 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49156.
2015-10-29 13:36:20 INFO  NettyBlockTransferService:59 - Server created on 49156
2015-10-29 13:36:20 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:36:20 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49156 with 503.3 MB RAM, BlockManagerId(driver, localhost, 49156)
2015-10-29 13:36:20 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:36:21 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:36:21 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49156 (size: 1631.0 B, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 107 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.131 s
2015-10-29 13:36:21 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:36:21 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49156 (size: 2.2 KB, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 4 ms
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1772 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.037 s
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.331664 s
2015-10-29 13:36:21 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:36:21 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:36:21 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10515, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14443, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49156 (size: 2.2 KB, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1775 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 6 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.007 s
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.017743 s
2015-10-29 13:36:21 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:36:21 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Got job 2 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Final stage: ResultStage 6(runJob at IntervalRDD.scala:82)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 4)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=16745, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=19401, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1631.0 B, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:49156 (size: 1631.0 B, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 4 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 3, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 3)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=21032, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 2.6 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=23688, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1633.0 B, free 503.3 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:49156 (size: 1633.0 B, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 5 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 5.0 with 1 tasks
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 5.0 (TID 4, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 3) in 19 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ShuffleMapStage 4 (parallelize at IntervalRDDSuite.scala:146) finished in 0.019 s
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 5.0 (TID 4)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:36:21 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 5)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List(ShuffleMapStage 5)
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 5.0 (TID 4). 1160 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 5.0 (TID 4) in 12 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ShuffleMapStage 5 (parallelize at IntervalRDDSuite.scala:128) finished in 0.024 s
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:36:21 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - waiting: Set(ResultStage 6)
2015-10-29 13:36:21 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Missing parents for ResultStage 6: List()
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=25321, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_5 stored as values in memory (estimated size 5.3 KB, free 503.3 MB)
2015-10-29 13:36:21 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=30785, maxMem=527727329
2015-10-29 13:36:21 INFO  MemoryStore:59 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 503.2 MB)
2015-10-29 13:36:21 INFO  BlockManagerInfo:59 - Added broadcast_5_piece0 in memory on localhost:49156 (size: 2.9 KB, free: 503.3 MB)
2015-10-29 13:36:21 INFO  SparkContext:59 - Created broadcast 5 from broadcast at DAGScheduler.scala:861
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 6 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Adding task set 6.0 with 1 tasks
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Starting task 0.0 in stage 6.0 (TID 5, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 13:36:21 INFO  Executor:59 - Running task 0.0 in stage 6.0 (TID 5)
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:36:21 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:36:21 INFO  Executor:59 - Finished task 0.0 in stage 6.0 (TID 5). 1776 bytes result sent to driver
2015-10-29 13:36:21 INFO  TaskSetManager:59 - Finished task 0.0 in stage 6.0 (TID 5) in 16 ms on localhost (1/1)
2015-10-29 13:36:21 INFO  TaskSchedulerImpl:59 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2015-10-29 13:36:21 INFO  DAGScheduler:59 - ResultStage 6 (runJob at IntervalRDD.scala:82) finished in 0.016 s
2015-10-29 13:36:21 INFO  DAGScheduler:59 - Job 2 finished: runJob at IntervalRDD.scala:82, took 0.070538 s
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:49156 in memory (size: 1631.0 B, free: 503.3 MB)
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_5_piece0 on localhost:49156 in memory (size: 2.9 KB, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 6
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:49156 in memory (size: 1633.0 B, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49156 in memory (size: 2.2 KB, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49156 in memory (size: 2.2 KB, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:36:22 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49156 in memory (size: 1631.0 B, free: 503.3 MB)
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:36:22 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:37:26 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:37:26 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:37:26 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:37:26 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:37:26 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:37:26 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:37:26 INFO  Remoting:74 - Starting remoting
2015-10-29 13:37:26 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49157]
2015-10-29 13:37:26 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49157.
2015-10-29 13:37:26 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:37:26 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:37:26 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-1ac92025-441a-4e8a-9bb9-07c2d0a87249
2015-10-29 13:37:26 INFO  MemoryStore:59 - MemoryStore started with capacity 506.8 MB
2015-10-29 13:37:26 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1bb2b8c4-ceae-4743-b558-42967987a1e8/httpd-509c4acc-0d35-4f7c-8b1a-1d1708f57f0f
2015-10-29 13:37:26 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:37:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:37:27 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49158
2015-10-29 13:37:27 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49158.
2015-10-29 13:37:27 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:37:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:37:27 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:37:27 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@fc21a77: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:37:27 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:37:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:37:27 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:37:27 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@87485d0: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:37:27 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:37:27 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 13:37:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:37:27 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4042
2015-10-29 13:37:27 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4042.
2015-10-29 13:37:27 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4042
2015-10-29 13:37:27 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:37:27 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:37:27 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49159.
2015-10-29 13:37:27 INFO  NettyBlockTransferService:59 - Server created on 49159
2015-10-29 13:37:27 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:37:27 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49159 with 506.8 MB RAM, BlockManagerId(driver, localhost, 49159)
2015-10-29 13:37:27 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:37:27 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:37:27 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:37:27 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49159 (size: 1631.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 76 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.094 s
2015-10-29 13:37:28 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:37:28 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49159 (size: 2.2 KB, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 7 ms
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 62 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.064 s
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.302805 s
2015-10-29 13:37:28 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:37:28 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Registering RDD 12 (parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Registering RDD 8 (parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Final stage: ResultStage 4(runJob at IntervalRDD.scala:82)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2, ShuffleMapStage 3)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 2, ShuffleMapStage 3)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 2 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146), which has no missing parents
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=10515, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 2.6 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=13171, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1631.0 B, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49159 (size: 1631.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 2 (ParallelCollectionRDD[12] at parallelize at IntervalRDDSuite.scala:146)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 2.0 with 1 tasks
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 3 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128), which has no missing parents
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 2539 bytes)
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 2.0 (TID 2)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=14802, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_3 stored as values in memory (estimated size 2.6 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(1633) called with curMem=17458, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 1633.0 B, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_3_piece0 in memory on localhost:49159 (size: 1633.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 3 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 3 (ParallelCollectionRDD[8] at parallelize at IntervalRDDSuite.scala:128)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 2.0 (TID 2). 1160 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 3, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 2.0 (TID 2) in 13 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ShuffleMapStage 2 (parallelize at IntervalRDDSuite.scala:146) finished in 0.013 s
2015-10-29 13:37:28 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:37:28 INFO  DAGScheduler:59 - running: Set(ShuffleMapStage 3)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - waiting: Set(ResultStage 4)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 3)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Missing parents for ResultStage 4: List(ShuffleMapStage 3)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 3). 1160 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ShuffleMapStage 3 (parallelize at IntervalRDDSuite.scala:128) finished in 0.015 s
2015-10-29 13:37:28 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:37:28 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - waiting: Set(ResultStage 4)
2015-10-29 13:37:28 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Missing parents for ResultStage 4: List()
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting ResultStage 4 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131), which is now runnable
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(5464) called with curMem=19091, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_4 stored as values in memory (estimated size 5.3 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  MemoryStore:59 - ensureFreeSpace(2939) called with curMem=24555, maxMem=531407831
2015-10-29 13:37:28 INFO  MemoryStore:59 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.9 KB, free 506.8 MB)
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Added broadcast_4_piece0 in memory on localhost:49159 (size: 2.9 KB, free: 506.8 MB)
2015-10-29 13:37:28 INFO  SparkContext:59 - Created broadcast 4 from broadcast at DAGScheduler.scala:861
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 4 (ZippedPartitionsRDD2[15] at zipPartitions at IntervalRDD.scala:131)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Adding task set 4.0 with 1 tasks
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Starting task 0.0 in stage 4.0 (TID 4, localhost, PROCESS_LOCAL, 2084 bytes)
2015-10-29 13:37:28 INFO  Executor:59 - Running task 0.0 in stage 4.0 (TID 4)
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:37:28 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 13:37:28 INFO  Executor:59 - Finished task 0.0 in stage 4.0 (TID 4). 1161 bytes result sent to driver
2015-10-29 13:37:28 INFO  TaskSetManager:59 - Finished task 0.0 in stage 4.0 (TID 4) in 14 ms on localhost (1/1)
2015-10-29 13:37:28 INFO  TaskSchedulerImpl:59 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2015-10-29 13:37:28 INFO  DAGScheduler:59 - ResultStage 4 (runJob at IntervalRDD.scala:82) finished in 0.015 s
2015-10-29 13:37:28 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.056991 s
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_4_piece0 on localhost:49159 in memory (size: 2.9 KB, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 5
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_3_piece0 on localhost:49159 in memory (size: 1633.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 4
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49159 in memory (size: 1631.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned shuffle 2
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned shuffle 1
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49159 in memory (size: 2.2 KB, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:37:28 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49159 in memory (size: 1631.0 B, free: 506.8 MB)
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:37:28 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:48:11 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:48:11 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:48:11 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:48:11 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:48:11 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:48:11 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:48:11 INFO  Remoting:74 - Starting remoting
2015-10-29 13:48:11 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49291]
2015-10-29 13:48:11 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49291.
2015-10-29 13:48:11 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:48:11 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:48:11 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-da561249-88bf-4c19-8ca6-6661c1b19a21
2015-10-29 13:48:11 INFO  MemoryStore:59 - MemoryStore started with capacity 516.5 MB
2015-10-29 13:48:11 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-82d2ff8f-fa3d-41e8-a0d7-29a86d79d100/httpd-2142338d-f0b6-438e-a2e6-385620916e90
2015-10-29 13:48:11 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49292
2015-10-29 13:48:12 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49292.
2015-10-29 13:48:12 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@559a240a: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:48:12 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@5d442e10: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:48:12 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@5684954f: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:48:12 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:48:12 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 13:48:12 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:48:12 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4043
2015-10-29 13:48:12 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4043.
2015-10-29 13:48:12 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4043
2015-10-29 13:48:12 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:48:12 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:48:12 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49293.
2015-10-29 13:48:12 INFO  NettyBlockTransferService:59 - Server created on 49293
2015-10-29 13:48:12 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:48:12 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49293 with 516.5 MB RAM, BlockManagerId(driver, localhost, 49293)
2015-10-29 13:48:12 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:48:13 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:48:13 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:48:13 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=541599989
2015-10-29 13:48:13 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 516.5 MB)
2015-10-29 13:48:13 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=541599989
2015-10-29 13:48:13 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 516.5 MB)
2015-10-29 13:48:13 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49293 (size: 1631.0 B, free: 516.5 MB)
2015-10-29 13:48:13 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:48:13 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:48:13 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:48:13 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:48:13 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:48:13 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 79 ms on localhost (1/1)
2015-10-29 13:48:13 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:48:13 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.093 s
2015-10-29 13:48:13 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:48:13 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:48:13 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:48:13 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=541599989
2015-10-29 13:48:13 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 516.5 MB)
2015-10-29 13:48:13 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=541599989
2015-10-29 13:48:13 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 516.5 MB)
2015-10-29 13:48:13 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49293 (size: 2.2 KB, free: 516.5 MB)
2015-10-29 13:48:13 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:48:13 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:48:13 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:48:13 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:48:13 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:48:13 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 13:48:13 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 13:48:13 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 13:48:13 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.043 s
2015-10-29 13:48:13 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:48:13 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.272699 s
2015-10-29 13:55:28 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49293 in memory (size: 2.2 KB, free: 516.5 MB)
2015-10-29 13:55:28 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 13:55:28 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49293 in memory (size: 1631.0 B, free: 516.5 MB)
2015-10-29 13:55:28 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 13:55:28 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 13:55:57 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 13:55:58 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 13:55:58 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 13:55:58 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 13:55:58 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 13:55:58 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 13:55:58 INFO  Remoting:74 - Starting remoting
2015-10-29 13:55:58 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49379]
2015-10-29 13:55:58 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49379.
2015-10-29 13:55:58 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 13:55:58 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 13:55:58 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-af506c07-55d0-47a8-b2ac-61eddb95aeb9
2015-10-29 13:55:58 INFO  MemoryStore:59 - MemoryStore started with capacity 508.9 MB
2015-10-29 13:55:58 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-e740169c-fb36-42ba-861d-0dc068818d8a/httpd-5a190ddc-3a51-43fa-b393-fc04d6bd3ff8
2015-10-29 13:55:58 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 13:55:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:58 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49380
2015-10-29 13:55:58 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49380.
2015-10-29 13:55:58 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 13:55:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@7f201d6a: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:55:58 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 13:55:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@45399d1: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:55:58 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 13:55:58 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@32134389: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:55:58 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:55:59 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 13:55:59 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:59 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:59 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@188c74ad: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 13:55:59 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 13:55:59 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 13:55:59 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 13:55:59 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4044
2015-10-29 13:55:59 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4044.
2015-10-29 13:55:59 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4044
2015-10-29 13:55:59 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 13:55:59 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 13:55:59 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49381.
2015-10-29 13:55:59 INFO  NettyBlockTransferService:59 - Server created on 49381
2015-10-29 13:55:59 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 13:55:59 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49381 with 508.9 MB RAM, BlockManagerId(driver, localhost, 49381)
2015-10-29 13:55:59 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 13:55:59 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 13:55:59 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 13:55:59 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 13:56:00 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=533672755
2015-10-29 13:56:00 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 508.9 MB)
2015-10-29 13:56:00 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=533672755
2015-10-29 13:56:00 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.9 MB)
2015-10-29 13:56:00 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49381 (size: 1631.0 B, free: 508.9 MB)
2015-10-29 13:56:00 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 13:56:00 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 13:56:00 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 13:56:00 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 13:56:00 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 13:56:00 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 69 ms on localhost (1/1)
2015-10-29 13:56:00 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 13:56:00 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.085 s
2015-10-29 13:56:00 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 13:56:00 INFO  DAGScheduler:59 - running: Set()
2015-10-29 13:56:00 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 13:56:00 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 13:56:00 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=533672755
2015-10-29 13:56:00 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 508.9 MB)
2015-10-29 13:56:00 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=533672755
2015-10-29 13:56:00 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.9 MB)
2015-10-29 13:56:00 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49381 (size: 2.2 KB, free: 508.9 MB)
2015-10-29 13:56:00 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 13:56:00 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 13:56:00 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 13:56:00 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 13:56:00 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 13:56:00 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 13:56:00 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 13:56:00 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (1/1)
2015-10-29 13:56:00 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.037 s
2015-10-29 13:56:00 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 13:56:00 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.268390 s
2015-10-29 14:13:22 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49381 in memory (size: 2.2 KB, free: 508.9 MB)
2015-10-29 14:13:22 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:13:22 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49381 in memory (size: 1631.0 B, free: 508.9 MB)
2015-10-29 14:13:22 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:13:22 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:13:24 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:13:24 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:13:24 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:13:24 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:13:24 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:13:24 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:13:24 INFO  Remoting:74 - Starting remoting
2015-10-29 14:13:24 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49422]
2015-10-29 14:13:24 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49422.
2015-10-29 14:13:24 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:13:24 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:13:24 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-5650e8c1-84b1-4b34-b007-bf21840120ac
2015-10-29 14:13:24 INFO  MemoryStore:59 - MemoryStore started with capacity 492.2 MB
2015-10-29 14:13:24 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-2a4accfb-47bc-44e5-ac12-f33fe443f20f/httpd-578e0ebb-038a-4dfd-889c-250a7d91af28
2015-10-29 14:13:24 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:13:24 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:24 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49423
2015-10-29 14:13:24 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49423.
2015-10-29 14:13:25 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@414d756c: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@2edd6d12: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4042: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@196d9864: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4043: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@11be5982: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4044: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@7d4f2558: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:13:25 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:13:25 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2015-10-29 14:13:25 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:13:25 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4045
2015-10-29 14:13:25 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4045.
2015-10-29 14:13:25 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4045
2015-10-29 14:13:25 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:13:25 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:13:25 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49424.
2015-10-29 14:13:25 INFO  NettyBlockTransferService:59 - Server created on 49424
2015-10-29 14:13:25 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:13:25 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49424 with 492.2 MB RAM, BlockManagerId(driver, localhost, 49424)
2015-10-29 14:13:25 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:13:26 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:13:26 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 14:13:26 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=516119592
2015-10-29 14:13:26 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 492.2 MB)
2015-10-29 14:13:26 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=516119592
2015-10-29 14:13:26 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 492.2 MB)
2015-10-29 14:13:26 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49424 (size: 1631.0 B, free: 492.2 MB)
2015-10-29 14:13:26 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:13:26 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:13:26 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 14:13:26 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:13:26 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:13:26 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 64 ms on localhost (1/1)
2015-10-29 14:13:26 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:13:26 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.079 s
2015-10-29 14:13:26 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:13:26 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:13:26 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:13:26 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=516119592
2015-10-29 14:13:26 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 492.2 MB)
2015-10-29 14:13:26 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=516119592
2015-10-29 14:13:26 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 492.2 MB)
2015-10-29 14:13:26 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49424 (size: 2.2 KB, free: 492.2 MB)
2015-10-29 14:13:26 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:13:26 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:13:26 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:13:26 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:13:26 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:13:26 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 14:13:26 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:13:26 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 14:13:26 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.044 s
2015-10-29 14:13:26 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:13:26 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.318420 s
2015-10-29 14:13:27 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49424 in memory (size: 2.2 KB, free: 492.2 MB)
2015-10-29 14:13:27 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:13:27 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49424 in memory (size: 1631.0 B, free: 492.2 MB)
2015-10-29 14:13:27 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:13:27 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:14:14 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4042
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4045
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4043
2015-10-29 14:14:14 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4044
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1bb2b8c4-ceae-4743-b558-42967987a1e8
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-82d2ff8f-fa3d-41e8-a0d7-29a86d79d100
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-e740169c-fb36-42ba-861d-0dc068818d8a
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-091374ae-5d69-49dc-88ba-bb513234b47a
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remoting shut down.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-2a4accfb-47bc-44e5-ac12-f33fe443f20f
2015-10-29 14:14:14 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:14:14 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:14:14 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Remote daemon shut down; proceeding with flushing remote transports.
2015-10-29 14:14:14 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-47efdc31-ca72-42ae-94cd-993bd0b24d49
2015-10-29 14:14:53 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:14:53 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:14:53 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:14:53 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:14:53 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:14:54 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:14:54 INFO  Remoting:74 - Starting remoting
2015-10-29 14:14:54 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49425]
2015-10-29 14:14:54 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49425.
2015-10-29 14:14:54 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:14:54 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:14:54 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-ed16b6fa-7f21-4ab4-bf03-fd51e32bf9ce
2015-10-29 14:14:54 INFO  MemoryStore:59 - MemoryStore started with capacity 491.7 MB
2015-10-29 14:14:54 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-5422cc83-65ce-4455-9a39-a16fbdd48d0e/httpd-2f19cd6b-d505-410d-a649-67f84729c862
2015-10-29 14:14:54 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:14:54 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:14:54 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49426
2015-10-29 14:14:54 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49426.
2015-10-29 14:14:54 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:14:55 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:14:55 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-10-29 14:14:55 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-10-29 14:14:55 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4040
2015-10-29 14:14:55 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:14:55 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:14:55 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49427.
2015-10-29 14:14:55 INFO  NettyBlockTransferService:59 - Server created on 49427
2015-10-29 14:14:55 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:14:55 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49427 with 491.7 MB RAM, BlockManagerId(driver, localhost, 49427)
2015-10-29 14:14:55 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:14:55 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:14:55 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:14:55 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 491.7 MB)
2015-10-29 14:14:56 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49427 (size: 1631.0 B, free: 491.7 MB)
2015-10-29 14:14:56 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 14:14:56 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:14:56 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 77 ms on localhost (1/1)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:14:56 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.094 s
2015-10-29 14:14:56 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:14:56 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:14:56 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:14:56 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(2300) called with curMem=8215, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49427 (size: 2.2 KB, free: 491.7 MB)
2015-10-29 14:14:56 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:14:56 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:14:56 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:14:56 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 6 ms
2015-10-29 14:14:56 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:14:56 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49427 in memory (size: 1631.0 B, free: 491.7 MB)
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 276 ms on localhost (1/1)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:14:56 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.276 s
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.605306 s
2015-10-29 14:14:56 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:14:56 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:14:56 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=6228, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=10156, maxMem=515553361
2015-10-29 14:14:56 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 491.7 MB)
2015-10-29 14:14:56 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49427 (size: 2.2 KB, free: 491.7 MB)
2015-10-29 14:14:56 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:14:56 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 14:14:56 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:14:56 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 1 ms
2015-10-29 14:14:56 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1161 bytes result sent to driver
2015-10-29 14:14:56 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 13 ms on localhost (1/1)
2015-10-29 14:14:56 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 14:14:56 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.015 s
2015-10-29 14:14:56 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.028232 s
2015-10-29 14:16:25 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49427 in memory (size: 2.2 KB, free: 491.7 MB)
2015-10-29 14:16:25 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 14:16:27 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:16:27 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:16:27 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:16:27 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:16:27 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:16:27 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:16:27 INFO  Remoting:74 - Starting remoting
2015-10-29 14:16:28 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49430]
2015-10-29 14:16:28 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49430.
2015-10-29 14:16:28 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:16:28 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:16:28 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-590f63e1-fa44-48ff-9c15-4c746fe469c6
2015-10-29 14:16:28 INFO  MemoryStore:59 - MemoryStore started with capacity 512.7 MB
2015-10-29 14:16:28 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1b2e32f6-5ff3-4b71-b999-aa980eb2132e/httpd-349ed300-7e90-4ec5-ac49-7720009895cf
2015-10-29 14:16:28 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:16:28 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:16:28 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49431
2015-10-29 14:16:28 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49431.
2015-10-29 14:16:28 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:16:28 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:16:28 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:16:28 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@67d2c26: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:16:28 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:16:28 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 14:16:28 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:16:28 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4041
2015-10-29 14:16:28 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4041.
2015-10-29 14:16:28 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4041
2015-10-29 14:16:28 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:16:28 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:16:28 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49432.
2015-10-29 14:16:28 INFO  NettyBlockTransferService:59 - Server created on 49432
2015-10-29 14:16:28 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:16:28 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49432 with 512.7 MB RAM, BlockManagerId(driver, localhost, 49432)
2015-10-29 14:16:28 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:16:28 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:16:29 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 512.7 MB)
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49432 (size: 1631.0 B, free: 512.7 MB)
2015-10-29 14:16:29 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 14:16:29 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:16:29 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 70 ms on localhost (1/1)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:16:29 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.085 s
2015-10-29 14:16:29 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:16:29 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:16:29 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=4287, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.8 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(2299) called with curMem=8215, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49432 (size: 2.2 KB, free: 512.7 MB)
2015-10-29 14:16:29 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:16:29 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:16:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:16:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-10-29 14:16:29 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (1/1)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:16:29 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.043 s
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.277539 s
2015-10-29 14:16:29 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:16:29 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:16:29 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10514, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14442, maxMem=537636372
2015-10-29 14:16:29 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 512.7 MB)
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49432 (size: 2.2 KB, free: 512.7 MB)
2015-10-29 14:16:29 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:16:29 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 14:16:29 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:16:29 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 14:16:29 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1161 bytes result sent to driver
2015-10-29 14:16:29 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 9 ms on localhost (1/1)
2015-10-29 14:16:29 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 14:16:29 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.011 s
2015-10-29 14:16:29 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.024504 s
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49427 in memory (size: 2.2 KB, free: 491.7 MB)
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49432 in memory (size: 2.2 KB, free: 512.7 MB)
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49432 in memory (size: 2.2 KB, free: 512.7 MB)
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:16:29 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49432 in memory (size: 1631.0 B, free: 512.7 MB)
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:16:29 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:17:30 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-10-29 14:17:30 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-10-29 14:17:30 INFO  SecurityManager:59 - Changing view acls to: akmorrow
2015-10-29 14:17:30 INFO  SecurityManager:59 - Changing modify acls to: akmorrow
2015-10-29 14:17:30 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(akmorrow); users with modify permissions: Set(akmorrow)
2015-10-29 14:17:30 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-10-29 14:17:31 INFO  Remoting:74 - Starting remoting
2015-10-29 14:17:31 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.32.39.246:49433]
2015-10-29 14:17:31 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 49433.
2015-10-29 14:17:31 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-10-29 14:17:31 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-10-29 14:17:31 INFO  DiskBlockManager:59 - Created local directory at /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/blockmgr-02a4bc95-2e80-4cee-883d-f1a1d1cfa122
2015-10-29 14:17:31 INFO  MemoryStore:59 - MemoryStore started with capacity 508.7 MB
2015-10-29 14:17:31 INFO  HttpFileServer:59 - HTTP File server directory is /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-960af11c-6380-47a2-af3d-e8daae3a2f2a/httpd-6907f847-3f4a-4685-8113-6eb638893faf
2015-10-29 14:17:31 INFO  HttpServer:59 - Starting HTTP Server
2015-10-29 14:17:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:17:31 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:49434
2015-10-29 14:17:31 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 49434.
2015-10-29 14:17:31 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-10-29 14:17:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:17:31 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4040: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:17:31 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@28da5226: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:17:31 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2015-10-29 14:17:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:17:31 WARN  AbstractLifeCycle:204 - FAILED SelectChannelConnector@0.0.0.0:4041: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:17:31 WARN  AbstractLifeCycle:204 - FAILED org.spark-project.jetty.server.Server@7d5d53ce: java.net.BindException: Address already in use
java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.open(SelectChannelConnector.java:187)
	at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:316)
	at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(SelectChannelConnector.java:265)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.spark-project.jetty.server.Server.doStart(Server.java:293)
	at org.spark-project.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:64)
	at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$connect$1(JettyUtils.scala:236)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.ui.JettyUtils$$anonfun$3.apply(JettyUtils.scala:246)
	at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$sp(Utils.scala:1913)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:1904)
	at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:246)
	at org.apache.spark.ui.WebUI.bind(WebUI.scala:136)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:465)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:465)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:138)
	at edu.berkeley.cs.amplab.spark.intervalrdd.IntervalRDDSuite.<init>(IntervalRDDSuite.scala:38)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at java.lang.Class.newInstance(Class.java:442)
	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:646)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:235)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:17:31 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:17:31 WARN  Utils:71 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2015-10-29 14:17:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-10-29 14:17:31 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4042
2015-10-29 14:17:31 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4042.
2015-10-29 14:17:31 INFO  SparkUI:59 - Started SparkUI at http://128.32.39.246:4042
2015-10-29 14:17:31 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-10-29 14:17:31 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-10-29 14:17:31 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49435.
2015-10-29 14:17:31 INFO  NettyBlockTransferService:59 - Server created on 49435
2015-10-29 14:17:31 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-10-29 14:17:31 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:49435 with 508.7 MB RAM, BlockManagerId(driver, localhost, 49435)
2015-10-29 14:17:31 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-10-29 14:17:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:17:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Registering RDD 4 (parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Got job 0 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Final stage: ResultStage 1(runJob at IntervalRDD.scala:82)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93), which has no missing parents
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(2656) called with curMem=0, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 2.6 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(1631) called with curMem=2656, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1631.0 B, free 508.7 MB)
2015-10-29 14:17:32 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:49435 (size: 1631.0 B, free: 508.7 MB)
2015-10-29 14:17:32 INFO  SparkContext:59 - Created broadcast 0 from broadcast at DAGScheduler.scala:861
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ShuffleMapStage 0 (ParallelCollectionRDD[4] at parallelize at IntervalRDDSuite.scala:93)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 1 tasks
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2630 bytes)
2015-10-29 14:17:32 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-10-29 14:17:32 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 1160 bytes result sent to driver
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 64 ms on localhost (1/1)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-10-29 14:17:32 INFO  DAGScheduler:59 - ShuffleMapStage 0 (parallelize at IntervalRDDSuite.scala:93) finished in 0.078 s
2015-10-29 14:17:32 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-10-29 14:17:32 INFO  DAGScheduler:59 - running: Set()
2015-10-29 14:17:32 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - failed: Set()
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which is now runnable
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(3952) called with curMem=4287, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(2320) called with curMem=8239, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:49435 (size: 2.3 KB, free: 508.7 MB)
2015-10-29 14:17:32 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 1 tasks
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:17:32 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 1)
2015-10-29 14:17:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:17:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 3 ms
2015-10-29 14:17:32 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 1). 1161 bytes result sent to driver
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (1/1)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - ResultStage 1 (runJob at IntervalRDD.scala:82) finished in 0.034 s
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Job 0 finished: runJob at IntervalRDD.scala:82, took 0.244011 s
2015-10-29 14:17:32 WARN  SparkContext:71 - sc.runJob with allowLocal=true is deprecated in Spark 1.5.0+
2015-10-29 14:17:32 INFO  SparkContext:59 - Starting job: runJob at IntervalRDD.scala:82
2015-10-29 14:17:32 INFO  MapOutputTrackerMaster:59 - Size of output statuses for shuffle 0 is 146 bytes
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Got job 1 (runJob at IntervalRDD.scala:82) with 1 output partitions
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Final stage: ResultStage 3(runJob at IntervalRDD.scala:82)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 2)
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Missing parents: List()
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177), which has no missing parents
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(3928) called with curMem=10559, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 3.8 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  MemoryStore:59 - ensureFreeSpace(2302) called with curMem=14487, maxMem=533389639
2015-10-29 14:17:32 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 508.7 MB)
2015-10-29 14:17:32 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:49435 (size: 2.2 KB, free: 508.7 MB)
2015-10-29 14:17:32 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at mapPartitions at IntervalRDD.scala:177)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Adding task set 3.0 with 1 tasks
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Starting task 0.0 in stage 3.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-10-29 14:17:32 INFO  Executor:59 - Running task 0.0 in stage 3.0 (TID 2)
2015-10-29 14:17:32 INFO  ShuffleBlockFetcherIterator:59 - Getting 1 non-empty blocks out of 1 blocks
2015-10-29 14:17:32 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 0 ms
2015-10-29 14:17:32 INFO  Executor:59 - Finished task 0.0 in stage 3.0 (TID 2). 1161 bytes result sent to driver
2015-10-29 14:17:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 3.0 (TID 2) in 7 ms on localhost (1/1)
2015-10-29 14:17:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2015-10-29 14:17:32 INFO  DAGScheduler:59 - ResultStage 3 (runJob at IntervalRDD.scala:82) finished in 0.008 s
2015-10-29 14:17:32 INFO  DAGScheduler:59 - Job 1 finished: runJob at IntervalRDD.scala:82, took 0.019873 s
2015-10-29 14:17:33 INFO  BlockManagerInfo:59 - Removed broadcast_2_piece0 on localhost:49435 in memory (size: 2.2 KB, free: 508.7 MB)
2015-10-29 14:17:33 INFO  ContextCleaner:59 - Cleaned accumulator 3
2015-10-29 14:17:33 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:49435 in memory (size: 2.3 KB, free: 508.7 MB)
2015-10-29 14:17:33 INFO  ContextCleaner:59 - Cleaned accumulator 2
2015-10-29 14:17:33 INFO  BlockManagerInfo:59 - Removed broadcast_0_piece0 on localhost:49435 in memory (size: 1631.0 B, free: 508.7 MB)
2015-10-29 14:17:33 INFO  ContextCleaner:59 - Cleaned accumulator 1
2015-10-29 14:17:33 INFO  ContextCleaner:59 - Cleaned shuffle 0
2015-10-29 14:42:44 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:42:44 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:42:44 INFO  SparkContext:59 - Invoking stop() from shutdown hook
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/api,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/static,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/executors,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/environment,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/storage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/stages,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2015-10-29 14:42:44 INFO  ContextHandler:843 - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2015-10-29 14:42:44 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4041
2015-10-29 14:42:44 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4042
2015-10-29 14:42:44 INFO  SparkUI:59 - Stopped Spark web UI at http://128.32.39.246:4040
2015-10-29 14:42:44 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:42:44 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:42:44 INFO  DAGScheduler:59 - Stopping DAGScheduler
2015-10-29 14:42:44 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:42:44 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:42:44 INFO  MapOutputTrackerMasterEndpoint:59 - MapOutputTrackerMasterEndpoint stopped!
2015-10-29 14:42:44 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:42:44 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:42:44 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:42:44 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:42:44 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:42:44 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:42:44 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:42:44 INFO  MemoryStore:59 - MemoryStore cleared
2015-10-29 14:42:44 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:42:44 INFO  BlockManager:59 - BlockManager stopped
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:42:44 INFO  BlockManagerMaster:59 - BlockManagerMaster stopped
2015-10-29 14:42:44 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-960af11c-6380-47a2-af3d-e8daae3a2f2a
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-1b2e32f6-5ff3-4b71-b999-aa980eb2132e
2015-10-29 14:42:44 INFO  SparkContext:59 - Successfully stopped SparkContext
2015-10-29 14:42:44 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Shutdown hook called
2015-10-29 14:42:44 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:59 - OutputCommitCoordinator stopped!
2015-10-29 14:42:44 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
2015-10-29 14:42:44 INFO  ShutdownHookManager:59 - Deleting directory /private/var/folders/s9/40npqrf17dn72t1wwk5tmjhs54h2pt/T/spark-5422cc83-65ce-4455-9a39-a16fbdd48d0e
2015-10-29 14:42:44 INFO  RemoteActorRefProvider$RemotingTerminator:74 - Shutting down remote daemon.
